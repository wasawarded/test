I S K O

Encyclopedia of Knowledge Organization

   home about ISKO join ISKO Knowledge Organization journal ISKO events
   ISKO chapters ISKO people ISKO publications Encyclopedia KO literature
   KO institutions ‚áó KOS registry üîí members contact us edited by Birger
   Hj√∏rland and Claudio Gnoli


Science mapping

     by Eugenio Petrovich

     Table of contents:
     1. Introduction
         1.1 Structure of the entry
         1.2 Three caveats about this entry
     2. A brief history of science mapping
         2.1 Ancestors of science maps
         2.2 Modern science mapping
     3. Building a science map: the general workflow
         3.1 Data sources for science mapping
         3.2 Field delineation
         3.3 Data cleaning and pre-processing
         3.4 Network extraction
     4. Types of science maps
         4.1 Citation-based maps: 4.1.1 The nodes in citation-based maps:
     publications and aggregates of publications; 4.1.2 The links in
     citation-based maps: direct citations, bibliographic coupling, and
     co-citations; 4.1.3 Normalization; 4.1.4 Visualization; 4.1.5
     Enriching the map
         4.2 Term-based maps: 4.2.1 Classic co-word analysis and the
     strategic diagrams; 4.2.2 Co-word analysis based on automatically
     extracted terms
         4.3 Other network-based maps: 4.3.1 Co-authorship networks;
     4.3.2 Interlocking editorship networks
         4.4 Other types of science maps: 4.4.1 Maps based on patents
     data; 4.4.2 Geographic maps of science
     5. The representation of time in science mapping
     6. Interpreting a science map
     7. Science maps and the philosophy of science
         7.1 On the objectivity of science maps
         7.2 Published science vs. science in the making
         7.3 The meaning of citations
     8. Science maps and science policy
     9. Conclusion
     Acknowledgments
     Endnotes
     References
     Appendix: Science mapping tools: (1) CiteSpace; (2) VOSviewer
     Colophon

     Abstract:
     Science maps are visual representations of the structure and
     dynamics of scholarly knowledge. They aim to show how fields,
     disciplines, journals, scientists, publications, and scientific
     terms relate to each other. Science mapping is the body of methods
     and techniques that have been developed for generating science maps.
     This entry is an introduction to science maps and science mapping.
     It focuses on the conceptual, theoretical, and methodological issues
     of science mapping, rather than on the mathematical formulation of
     science mapping techniques. After a brief history of science
     mapping, we describe the general procedure for building a science
     map, presenting the data sources and the methods to select, clean,
     and pre-process the data. Next, we examine in detail how the most
     common types of science maps, namely the citation-based and the
     term-based, are generated. Both are based on networks: the former on
     the network of publications connected by citations, the latter on
     the network of terms co-occurring in publications. We review the
     rationale behind these mapping approaches, as well as the techniques
     and methods to build the maps (from the extraction of the network to
     the visualization and enrichment of the map). We also present
     less-common types of science maps, including co-authorship networks,
     interlocking editorship networks, maps based on patents‚Äô data, and
     geographic maps of science. Moreover, we consider how time can be
     represented in science maps to investigate the dynamics of science.
     We also discuss some epistemological and sociological topics that
     can help in the interpretation, contextualization, and assessment of
     science maps. Then, we present some possible applications of science
     maps in science policy. In the conclusion, we point out why science
     mapping may be interesting for all the branches of meta-science,
     from knowledge organization to epistemology.

                                                            [top of entry]

1. Introduction

   Science maps, also known as scientographs, bibliometric network
   visualizations, and knowledge domain maps, are visual representations
   of the structure and dynamics of scholarly knowledge. They aim to show
   how ‚Üí disciplines, fields, specialties, authors, keywords, or
   publications relate to each other (B√∂rner, Chen and Boyack 2005; Chen
   2013; Osinska and Malak 2016; Rafols, Porter and Leydesdorff 2010;
   Small 1999; Van Raan 2019). Science maps are usually generated based on
   the analysis of large collections of scientific ‚Üí documents (B√∂rner
   2010; Cobo et al. 2011b).

   Science mapping is the body of methods and techniques that have been
   developed to generate science maps. Science mapping has a long
   tradition in bibliometrics and scientometrics, i.e., the quantitative
   studies of science (Chen 2017; Van Raan 2019). In the last decades, it
   has increasingly become an interdisciplinary area, witnessing important
   contributions from ‚Üí data science, where science mapping belongs to the
   larger and increasingly important area of information visualization
   (B√∂rner, Chen and Boyack 2005).

   Science maps have several applications. They help to answer questions
   such as: What are the main topics within a certain scientific domain?
   How do these topics relate to each other? How has a certain scientific
   domain developed over time? Who are the key actors (researchers,
   institutions, journals) of a scientific field? Science maps help to
   investigate how the structural units of science relate one another at
   the micro and macro level (Leydesdorff 1987), what factors determine
   the emergence of new scientific fields and the development of
   interdisciplinary areas (Leydesdorff and Goldstone 2014), and, more
   generally, how scientific change functions (Leydesdorff 2001;
   Lucio-Arias and Leydesdorff 2009). At the same time, the information
   made accessible by science maps can be highly relevant for science
   policy purposes.

   Science maps, and especially the global maps, also known as ‚Äúatlases of
   science‚Äù (see Section 3.2: Field delineation), can help to ‚Üí classify
   the sciences by showing their mutual relationships (e.g., by showing
   the citation flows between fields). In this sense, science maps are
   useful tools in ‚Üí knowledge organization and have been used to build
   classification systems with a bottom-up approach (see e.g., Waltman and
   van Eck 2012). However, standard methods of science mapping are not
   based on and do not result in semantic relationships between categories
   (e.g., genus-species relation) but association measures between units
   of analysis (e.g., co-citation strength between publications, or
   co-authorship association between authors). The closest to semantic
   relations that can be produced by standard science mapping approaches
   is the relation of inclusion obtained by clustering techniques, in
   which higher-order clusters include lower-order clusters (see Section
   4.1.5: Enriching the map). Science maps, hence, are not meant to
   replace taxonomies, classificatory schemes, ontologies, and other
   classic ‚Üí knowledge organization systems (KOS) (Hj√∏rland 2013;
   Mazzocchi 2018). Rather, they can integrate them by providing extra
   information on the structure of science based on the analysis of
   citation networks and other kinds of scientific networks. At the same
   time, the application of science maps is not restricted to knowledge
   organization but extends to the sociology of science and science
   policy.

                                                            [top of entry]

1.1 Structure of the entry

   This article is an introduction to science maps and science mapping
   methodology. It is structured as follows. Section 2 offers a brief
   overview of the history of science mapping. Section 3 presents the
   standard workflow behind a science map and the preliminary steps of
   science mapping: data collection, field delineation, data
   pre-processing, and network extraction. Section 4 examines the
   different types of science maps that can be generated from network
   data. Section 4.1 is devoted to citation-based maps, i.e., those maps
   that are based on publications (or aggregates of publications) and
   citations (or citation-based relations) between publications. This
   section describes in details some procedures that are common also to
   other science maps, such as the normalization of the raw relatedness
   scores, and the two most diffused visualization approaches, the
   graph-based and the distance-based. It also presents some techniques
   that can be used to complement the results of mapping and ease the
   interpretation of science maps, such as clustering. Section 4.2
   discusses term-based maps, i.e., those maps that are based on the
   analysis of the titles, abstracts, keywords or bibliographic
   descriptors of scientific publications. We will first present the
   classic co-word analysis as developed in the sociology of science and
   then focus on maps based on terms extracted automatically with natural
   language processing techniques. Section 4.3 briefly overviews science
   maps based on co-authorship and interlocking editorship networks,
   whereas Section 4.4 reviews science maps based on patents and
   geographic maps of science. Section 5 discusses different strategies to
   include the dimension of time into science maps. Section 6 is devoted
   to the last step in the science mapping workflow, namely
   interpretation, and to discuss some general issues of science mapping,
   such as the importance of the level of analysis and the applicability
   of science mapping to the humanities. In Section 7, some
   epistemological topics, which bridge across science mapping, sociology
   of science, and philosophy of science are discussed: the objectivity of
   science maps, the relationship between the published side of science
   and the scientific practice, and the meaning of citations. Section 8
   overviews the potential applications of science maps in science policy.
   Lastly, the Conclusion will sketch how science mapping may be of
   interest for all the disciplines that compose meta-science. In the
   Appendix, two tools currently available for producing science maps,
   CiteSpace and VOSviewer, are briefly reviewed.

                                                            [top of entry]

1.2 Three caveats about this entry

   This entry focuses on conceptual, theoretical, and methodological
   issues of science mapping rather than on the rigorous mathematical
   formulation of science mapping techniques, as the basic ideas behind
   the techniques can often be understood without reference to the formal
   machinery. Relevant technical literature will be pointed out in the
   references.

   Secondly, we will focus on the methodology of science mapping, rather
   than on specific exemplars of science maps. We aim to provide the
   readers with the tools to understand and independently assess the
   science maps they will encounter (or produce!), rather than offer our
   opinion on existing maps. A wonderful collection of science maps can be
   found in the Atlas of Science by Katy B√∂rner (B√∂rner 2010) and in the
   exhibit Places and Spaces: Mapping Science, which popularizes the topic
   of science mapping to the large public all over the world since 2005
   [1].

   Lastly, science mapping is not a static research field, but it is
   constantly moving forward. New mapping methods are developed, old
   algorithms are dismissed, science mapping tools are refined, larger
   maps are built as higher computing capacity becomes available.
   Therefore, it is not uncommon to find disagreement in the current
   science maps literature (e.g. Boyack and Klavans 2010). In this
   article, we will try as far as possible to remain neutral concerning
   these discussions, presenting to the reader the different options
   without taking a position.

                                                            [top of entry]

2. A brief history of science mapping

   Modern science mapping relies on the data provided by large,
   multidisciplinary databases that index vast portions of the scientific
   literature (see Section 3.1: Data sources for science mapping). Before
   the creation of these databases in the 1960s, it was virtually
   impossible to generate science maps in the modern sense. The idea of
   representing the structure of human knowledge by visual aids, however,
   dates far back in history.

                                                            [top of entry]

2.1 Ancestors of science maps

   Already in the Middle Age, the relationships between the seven liberal
   arts, comprising the trivium and quadrivium, were visually represented
   by allegories [2]. However, the most popular visual metaphor in history
   for visualizing knowledge has been the tree (Lima 2014). Its origins
   can be traced back to Aristotle, and to the Isagoge, an introduction to
   Aristotle‚Äôs logic written by Porphyry in the 3rd Century. In the 13th
   Century, Ramon Llull depicted a tree of the sciences in his Arbor
   Scientiae (1295). Descartes, in the Principia Philosophiae (1644), used
   the same image to explain the relationship between metaphysics,
   physics, and the applied sciences. During the Enlightenment, the famous
   Encyclop√©die of Diderot and d‚ÄôAlambert contained a tree-like taxonomy
   of human knowledge (‚ÄúSyst√®me figur√© des connaissances humaines‚Äù).
   Similar structures can be found also in the 19th Century, in
   philosophical treaties on the classification and organization of the
   sciences [3].

                                                            [top of entry]

2.2 Modern science mapping

   The tree-like representations of the sciences in the past had usually a
   philosophical aim. They served to reflect on the most general
   principles that underlie human knowledge. At the same time, they aimed
   at organizing scientific and scholarly disciplines, by creating
   hierarchies between them. Often, they were proposed with a normative
   spirit: more than describing the actual organization of knowledge, they
   wanted to reform and improve it. What they all shared was a ‚Äútop-down‚Äù
   approach. Starting from a certain idea of human knowledge and a certain
   set of classificatory categories, a taxonomy was devised, which was
   then used to categorize the individual items of knowledge, such as
   books or scientific papers. The Dewey Decimal Classification, a ‚Üí
   library classification system developed in 1876, epitomizes such a
   top-down approach.

   The creation of the Science Citation Index (SCI) in the 1960s by Eugene
   Garfield at the Institute for Scientific Information, allowed for a
   first time a bottom-up approach. As we will see better in the next
   sections (see Section 3.4: Network extraction), the SCI indexed the
   citation-links between the articles published in scientific journals.
   In this way, it allowed to reconstruct the network in which each
   scientific article is embedded, and, by connecting all these networks,
   to reconstruct the structure of entire scientific areas. In this way, a
   new method to map human knowledge became possible. The historian of
   science Derek De Solla Price was the first to suggest such an idea in
   1965 (Price 1965). Garfield himself proposed the method of
   historiographs to reconstruct the temporal development of scientific
   ideas by analyzing the citation links between publications (Garfield
   1973) (see Section 5: The representation of time in science mapping).

   In the 1960s and 1970s, two new techniques, both based on citations,
   were developed to measure the association of scientific papers:
   bibliographic coupling (Kessler 1963) and co-citation (Small 1973;
   Marshakova 1973). They soon became standard techniques for science
   mapping (see Section 4.1.2: The links in citation-based maps). Henry
   Small started to use co-citation analysis to map scientific areas and
   study their evolution over time. He generated the first science maps
   based on co-citation analysis in 1977 to study the field of collagen
   research (Small 1977).

   In the 1980s, new methods of analysis were developed, such as author
   co-citation analysis (White and Griffith 1981) and co-word analysis
   (Callon et al. 1983). At the same time, the technical aspects of
   science mapping were discussed and sometimes disputed (Leydesdorff
   1987). The 1990s saw important advancements in computer visualization
   techniques and, in 1991, the first science mapping program for the
   personal computer, SCI-map, was made available. In the 2000s, the
   improvement of computer capacity allowed to produce the first global
   maps of science, based on the analysis of thousands of journals and
   millions of publications. New user-friendly science mapping tools, such
   as CiteSpace and VOSviewer, were launched in the 2010s, so that
   nowadays also the non-experts can generate their own science maps. In
   the last twenty years, science mapping has become an increasingly
   interdisciplinary area, with important contributions from computer
   scientists and experts in information visualization, and the last ten
   years have seen what has been called a ‚ÄúCambrian explosion of science
   maps‚Äù (B√∂rner, Theriault and Boyack 2015) [4].

                                                            [top of entry]

3. Building a science map: the general workflow

   The construction of a science map follows a general workflow that
   comprises the following steps (B√∂rner, Chen and Boyack 2005; Cobo et
   al. 2011b):
    1. Data collection. Based on the research question of the analyst, the
       data for the mapping are collected. In principle, any relational
       feature of the scientific activity can be collected by different
       methods. In practice, however, most science mapping studies are
       based on data stored in bibliographic data sources. Hence, the data
       collection consists in individuating appropriate queries to extract
       bibliographic data from those sources.
    2. Pre-processing. The raw data are cleaned and, if needed, further
       selected (for instance, only publications cited over a certain
       threshold are retained). This step is crucial since the goodness of
       the mapping depends on the quality of the underlying data.
    3. Network extraction. Depending on the chosen unit of analysis
       (publication, term, author, journal, institution, etc.) and the
       kind of analysis (direct linkage, co-citation, bibliographic
       coupling, co-word analysis, etc.) the corresponding network is
       extracted from the data.
    4. Normalization. Usually, the relatedness scores (e.g., the raw
       number of co-citations between publications) are not directly used
       to generate the science maps because experience and experimentation
       have shown that they can create distortions due to the different
       sizes of the items (Boyack and Klavans 2019). It is thus a common
       practice to perform normalization on the raw values using
       similarity measures.
    5. Visualization. There are different options to visualize the
       network. In graph-based visualizations, graph drawing algorithms
       are used. In distance-based visualizations, dimensionality
       reduction techniques are used to plot the data into a
       two-dimensional (or, more rarely, three-dimensional) layout, so
       that the distances between the points on the map reflect the
       similarity of the units of analysis.
    6. Enrichment. The elements of the map can be enriched to provide more
       information. Frequently, clustering techniques are used to find
       groups of similar nodes and colors are used to distinguish nodes
       belonging to different clusters.
    7. Interpretation. The science map is interpreted, usually with the
       help of experts in the mapped domain. The visual nature of the map
       enables the recognition of patterns and structures, which can
       provide an answer to research questions or help in addressing
       science policy issues.

   In the next sections, we focus on the first three steps of science
   mapping: data collection, data pre-processing, and network extraction.
   Based on the type of network extracted, different types of science maps
   can be generated. In Section 4, each type is examined in detail. Note
   that citation-based maps will allow us to describe the steps of
   normalization, visualization, and enrichment that recur also in the
   generation of other types of science maps. Section 5 is an excursus on
   how time can be represented in science maps, whereas Section 6
   discusses the last phase of science mapping, i.e., the interpretation.

                                                            [top of entry]

3.1 Data sources for science mapping

   Science mapping is a methodology that can be applied, in principle, to
   a variety of data regarding the scientific enterprise. In practice,
   however, the main data sources for science mapping are bibliographic
   databases. Other types of data must be collected by the analysts.

   Bibliographic databases used to this purpose are large
   multi-disciplinary databases that collect the ‚Üí metadata of academic
   publications (authors, title, abstract, keywords, affiliation of the
   authors, publication year, etc.) along with their citations (hence
   their name of citation indexes). The main citation indexes are
   Clarivate‚Äôs Web of Science (WoS), Elseviers‚Äô Scopus, and Google
   Scholar.

   Recently, two open bibliographic databases have joined Google Scholar:
   Microsoft Academic (launched in 2006, it stopped being updated in 2012
   and was relaunched in 2016 [5]) and Dimensions (launched in 2019 [6]).
   Moreover, in 2017 Crossref, a not-for-profit organization of
   publishers, has made its citation data openly available. Comparisons
   between the coverage of these new databases and the coverage of
   traditional databases are currently being undertaken by the
   bibliometric community (Visser, van Eck and Waltman 2020; Harzing
   2019).

   In addition to multi-disciplinary databases, there are also specialized
   databases, focusing on specific disciplines (e.g., PubMed for medicine,
   and PsycInfo for psychology). Patent data can be retrieved from
   specific data sources such as the United States Patent and Trademark
   Office [7], Google patents [8] and the database of the European Patent
   Office [9].

   More detailed information about these databases can be found in ‚Üí the
   dedicated entry of this encyclopedia (Ara√∫jo, Castanha and Hj√∏rland
   2020).

                                                            [top of entry]

3.2 Field delineation

   To produce a science map, we first need to individuate a set of
   publications that reasonably represent the target of the mapping. In
   bibliometrics, this step is often called field delineation. Field
   delineation is the collection of documents that are both relevant and
   specific for the purpose of the mapping (Zhao 2009).

   At this point, an important difference can be made between global and
   local maps of science. Global maps of science (also known as ‚Äúatlases
   of science‚Äù) aim to map the whole science (B√∂rner et al. 2012; Boyack,
   Klavans and B√∂rner 2005; Boyack and Klavans 2019). To produce such
   maps, the main criteria is to maximize coverage. Local maps of science,
   on the other hand, focus on a limited portion of the scientific
   literature (Rafols, Porter and Leydesdorff 2010). Such a portion can be
   a scientific field, a specialty, a research topic, or the publication
   output of a university. In all these cases, the accurate selection of
   the target publications is a crucial step since an unrepresentative or
   wrong set of publications will produce a misrepresentation of the
   target.

   Following Zitt and colleagues, we distinguish three general strategies
   for field delineation: (A) rely on external formalized resources, such
   as ready-made science classifications; (B) create ad hoc information
   retrieval searches; (C) use network exploration resources (i.e.,
   science mapping itself) (Laurens, Zitt and Bassecoulard 2010; Zitt et
   al. 2019; Zitt and Bassecoulard 2006).

   The first strategy is based on ready-made classifications, such as the
   ones used by Web of Science or Scopus to classify their records. Other
   classificatory schemes are produced in institutional settings (e.g., by
   research evaluation agencies or by research councils) and, clearly, by
   libraries. Note that sometimes the journal, rather than the individual
   article, is the unit of classification, with the articles inheriting
   the category of the journals where they are published. Following this
   first strategy, representative literature is retrieved by using these
   ready-made classifications at different levels of granularity
   (scientific field, specialty, sub-area, etc.). An evident shortcoming
   of this strategy is that it heavily relies on the goodness of the
   chosen classifications.

   The second strategy is based on creating, usually in close interaction
   with domain experts, ad hoc searches to query the databases. These
   queries can potentially include any searchable part of the
   bibliographic records: words in titles and abstracts, keywords,
   authors, affiliations, journals, dates, references, and so on. A
   typical query combines a search for specialized journals and a lexical
   search in complement. Note that the starting queries can be refined,
   for instance by citation analysis. Once a core set of publications,
   journals or even key authors is determined, new records are added by
   following the citations (articles citing the core set) or the
   references (articles cited by the core set), in an iterative process.

   The third strategy relies on science mapping methods and, in
   particular, on clustering. The basic idea is to use bottom-up
   clustering techniques that group publications based not on a
   classificatory scheme, but on their reciprocal relations (for instance,
   their co-citation strength, see Section 4.1.2: The links in
   citation-based maps). Techniques of network analysis, as well as
   experts‚Äô knowledge, are then used to select the relevant clusters. By
   iterating this procedure, an increasingly precise field delineation is
   obtained.

   All these approaches involve the double risk of losing relevant
   publications and introducing noise (not relevant publications) in the
   dataset (Zitt et al. 2019). In fact, there is no fit-to-all solution to
   field delineation. From an operative point of view, a good strategy is
   to combine recursively the different approaches, checking each time the
   set of retrieved publications and refining accordingly the queries (an
   example of this approach can be found in Chen 2017).

   However, it is important to remember that, from a theoretical point of
   view, there is no ground truth basis for defining research domains in a
   ‚Äúpurely objective‚Äù way. As the ongoing discussion about research areas
   definition and classification shows, research classification should be
   conceived as a social process involving multiple actors, from
   researchers to journals to research evaluation agencies, rather than as
   a static photograph of the structure of science. Classificatory schemes
   as well as the boundaries between areas are constantly negotiated and
   reshaped under the pressure of different social systems and
   infrastructures (Sugimoto and Weingart 2015). As these systems serve
   different purposes and are governed by different logics, frictions and
   inconsistences between the classificatory schemes they produce are to
   be expected (√Östr√∂m, Hammarfelt and Hansson 2017). For instance, an
   article can be classified as belonging to research area X based on the
   institutional affiliation of its authors and to research area Y based
   on the topic of the journal where it is published. Even if field
   delineation is the first step in many bibliometric analyses, including
   science mapping, its theoretical stakes should not be underestimated.

                                                            [top of entry]

3.3 Data cleaning and pre-processing

   When the field delineation is completed and the datasets are retrieved
   from bibliographic databases, the data consist basically of large
   tables, in which each row corresponds to a publication and the columns
   represent the available meta-data of that publication (e.g., title,
   authors, abstract, publication year, journal, cited references, etc.).
   Retrieved data usually contain errors, for instance, misspelling of
   author names, errors in the cited references, journal titles, and so
   on. Cleaning the data is a pivotal step in the science mapping workflow
   because the quality of the results depends on the quality of the data.
   This task, however, can be highly time-consuming and can present
   difficult issues, such as the disambiguation of authors with homonym
   names and the merging of authors with multiple names (Strotmann and
   Zhao 2012).

   After the cleaning, the data can be pre-processed. They can be divided
   into different time sub-periods to carry out longitudinal studies (see
   Section 5: The representation of time in science mapping), or a portion
   of the retrieved data can be furtherly selected based on some measure,
   such as the most cited articles, the most productive authors, or the
   journals with the highest performance metrics.

                                                            [top of entry]

3.4 Network extraction

   In general, a network is a structure made of nodes (also called
   vertices) and links (also called edges). It can be represented as a
   graph or as a matrix. Networks are valuable tools to represent and
   study a great variety of natural and social phenomena, from the lineage
   of a family to patterns of contracts among firms, to the spreading of a
   virus (Barab√°si 2014).

   In science mapping, we are interested in those networks that can
   capture the structure of science at different levels and from different
   points of view. In fact, these networks are the basic structure on
   which science maps are built.

   From the same set of bibliographic records, it is possible to generate
   different networks, depending on the type of nodes and links we decide
   to focus on. The nodes will represent the unit of analysis of the final
   map, whereas the links will represent the type of relationship
   displayed.

                                                            [top of entry]

4. Types of science maps

   Science maps can be classified into different types depending on the
   kind of data, and hence the kind of network, they are based on. In
   principle, any feature of the scientific enterprise that can be
   represented in relational terms, i.e., as a network of nodes and links,
   can be used to generate a science map. In citation-based maps, the
   units of analysis (the nodes) are publications or aggregates of
   publications (e.g., journals or authors), and the relationships between
   them (the links) are citations or association measures based on
   citations (bibliographic coupling and co-citation). In term-based maps,
   the units of analysis are textual items (themes, keywords or terms) and
   the relationships are co-occurrence frequencies (e.g., the number of
   times two keywords are used together in a set of publications). In
   co-authorship maps, the units are the authors and the links are the
   number of co-authored publications. In interlocking editorship maps,
   the units are the journals and the links are the number of persons who
   are shared between the editorial boards of two journals). In addition
   to these, there are also science maps based on patents data and
   geographic maps of science, which will be the topic of Section 4.4.

                                                            [top of entry]

4.1 Citation-based maps

   4.1.1 The nodes in citation-based maps: publications and aggregates of
   publications

   In the most basic citation-based map, the nodes represent individual
   publications and the links the citations (reference-links) among them.
   An example of citation network is provided in Fig. 1, where it is
   visualized as a directed network in which nodes represent publications
   and arrows represent the reference-links (citations) between them. Some
   publications are both citing and cited (e.g., publication a), some
   publications are only cited (e.g., publication f), and some
   publications cite without being cited (e.g., publication e).

      Fig. 1: Example of citation network Figure 1: Example of citation
   network. Nodes represent document and arrows the citations between them

   The same information can be represented as an adjacency matrix, whose
   elements indicate whether pairs of nodes are connected (‚Äúadjacent‚Äù) in
   the network or not. When the publication in the row cites a publication
   in the column, the corresponding element in the matrix is 1, 0
   otherwise [10].

       a b c d e f g h
     a 0 1 1 1 0 0 0 0
     b 0 0 1 0 0 0 0 1
     c 0 0 0 0 0 1 1 0
     d 0 0 0 1 0 0 0 0
     e 1 0 1 0 0 0 1 0
     f 0 0 0 0 0 0 0 0
     g 0 0 0 0 0 0 0 0
     h 0 0 0 0 0 0 0 0

   Since publications are provided with meta-data, such as their authors
   or the journals in which they are published, it is possible to build
   aggregates of publications sharing the same meta-data (Radicchi,
   Fortunato and Vespignani 2012). By aggregating publications at a higher
   and higher level, we can reach higher units of the analysis and
   networks based on new types of nodes.

   To understand this mechanism, we show how to build a journal citation
   network (Leydesdorff 2004; McCain 1991) starting from the document
   citation network of Fig. 1. We start by coloring the nodes according to
   the journals where they are published, and the citation links according
   to the journal to which they point (Fig. 2).

      Fig. 2: Citation network with document-nodes colored based on the
       journal they were published in Figure 2: Citation network with
   document-nodes colored based on the journal they were published in. The
     color of the arrows corresponds to the color of the citing journal

   The journal citation network is obtained by substituting each article
   with its journal of publication and then using the journals as nodes of
   the network. A link between two journals is drawn when they exchange at
   least one citation. Note that in this new network, it is possible to
   provide links with weight, that is the number of citations that each
   journal receives from other journals (or from itself). In the previous
   network, there was not a proper weight but only an on/off relationship
   (presence of a reference-link or not). There are also some loops,
   produced by articles citing articles published in the same journal
   (these loops correspond to journal self-citations). The resulting
   journal citation network is shown in Fig. 3.

      Fig. 3: Example of journal citation network Figure 3: Example of
         journal citation network. Out-citations, in-citations, and
    self-citations between journals are colored, respectively, in green,
                             orange, and violet

   By the same aggregation process, we can construct author citation
   networks (e.g., McCain 1990; Radicchi et al. 2009), or reach higher
   units of analysis, such as institutions and even countries (e.g.,
   Gl√§nzel 2001).

                                                            [top of entry]

4.1.2 The links in citation-based maps: direct citations, bibliographic
coupling, and co-citations

   Until now, we considered only citations as links in the citation
   network. The presence of a reference-link between two publications
   usually attests that they are somehow associated, for instance, that
   they share the same topic or research method (see Section 7.3: The
   meaning of citations). Maps in which the links are direct citations are
   called ‚Äúdirect-linkage‚Äù or ‚Äúcross-citations‚Äù or ‚Äúinter-citation‚Äù maps
   (Waltman and van Eck 2012). In science mapping, however, there are two
   other common techniques used to measure the relatedness or strength of
   association of publications (or their aggregates): bibliographic
   coupling (Kessler 1963) and co-citation (Small 1973; Marshakova 1973).

   In bibliographic coupling, a link between two publications is
   established when they share at least one publication in their
   respective bibliographies, i.e. when they have at least one reference
   in common. The weight of the link is proportional to the number of
   shared references. Co-citation is, in a certain sense, the reverse of
   bibliographic coupling. In a co-citation network, a link is drawn
   between two publications if they are cited together at least by a third
   publication, and the weight of the link (the so-called co-citation
   strength) is proportional to the number of common citations they gather
   (i.e., the number of co-citations).

   Fig. 4 shows the bibliographic coupling network generated from the
   citation network of Fig. 1. Note that publication f has no link with
   other publications because, in our example, it did not have any cited
   reference (i.e., no out-going link).

   Fig. 4: Bibliographic coupling network generated based on the citation
    network in Fig. 1 Figure 4: Bibliographic coupling network generated
   based on the citation network in Fig. 1. Nodes are publications, links
   show bibliographic coupling between publications. Note that publication
    f has no bibliographic coupling links with other publications in the
                                   network

   Fig. 5 shows the co-citation network. Analogously, publication e has no
   link with other publications because it had no citations (i.e., no
   incoming link).

   Fig. 5: Co-citation network generated based on the citation network in
    Fig. 1 Figure 5: Co-citation network generated based on the citation
      network in Fig. 1. Nodes are publications, links show co-citation
   between publications. Note that publication e has no co-citation links
                   with other publications in the network

   Note that citations are directed links because we can distinguish
   between a sender and a receiver of the citation. In network theory
   terminology, they are called arcs (Wasserman and Faust 1994). In
   contrast, bibliographic coupling and co-citation links are un-directed
   links because bibliographic couplings and co-citations are symmetrical.
   In network theory terminology, they are called edges (Wasserman and
   Faust 1994).

   Starting from a matrix whose rows are the citing publications and
   columns are the cited publications, it is possible to derive by matrix
   algebra operations the two co-occurrence matrices representing the
   bibliographic coupling network or the co-citation network (Van Raan
   2019).

   Note that direct citations, bibliographic coupling, and co-citation
   analysis can be applied not only to single publications, but also to
   aggregates of publications. For instance, if authors are used as units
   in co-citation analysis, we have author co-citation analysis (e.g.,
   White and McCain 1998; Kreuzman 2001), if journals are used as units,
   we have journal co-citation analysis (e.g., McCain 1991). By combining
   in this way methods and units of analysis, several types of
   bibliometric networks can be generated (Waltman and van Eck 2014). Fig.
   6 shows an example of co-citation map using individual publications as
   units of analysis.

   Fig. 6: Example of co-citation map (click to enlarge) Figure 6: Example
     of co-citation map (click to enlarge). The field mapped is analytic
   philosophy. The nodes represent documents. A link is drawn between two
   nodes when they are co-cited. Size of the nodes is proportional to the
   number of citations gathered by the document; thickness of the links is
   proportional to the co-citation strength; nodes‚Äô colors indicate the
   cluster to which they are attributed by the clustering algorithm. Nodes
     are positioned according to their co-citation strength, so that the
   more frequently they are cited together, the closer they appear on the
             map. The visualization was produced with VOSviewer.

                                                            [top of entry]

4.1.3 Normalization

   Usually, the raw frequencies of citations, bibliographic couplings or
   co-citations are not directly used as input of the visualization
   process that leads to the final form of the science map. This is
   because the raw frequencies do not properly reflect the similarity
   between the items (van Eck and Waltman 2009). To understand why,
   suppose that department AA and department BB publish comparable
   articles, but department AA, having more researchers than department
   BB, publishes 10 times more articles. Other things being equal, one
   would expect that the articles from department AA will receive in total
   about ten times as many citations as the articles from department BB
   and thus to have about ten times as many co-citations with other
   departments in the same discipline as department BB. However, the fact
   that department AA has more co-citations with other departments than
   department BB does not indicate that it is more similar to other
   departments than department BB. It only shows that department AA
   publishes more articles than department BB because it is bigger. To
   correct such a distortion due to the different size of the units of
   analysis, we need to transform the raw co-citation scores, adjusting
   them by some stable quantity, an operation called ‚Äúnormalization‚Äù (Eck
   et al. 2010).

   In science mapping, similarity measures are used to perform such a
   normalization. Following Ahlgren and colleagues, we distinguish two
   main approaches to calculating these similarities: the local or direct
   and the global or indirect (Ahlgren, Jarneving and Rousseau 2003). In
   the former approach, the focus is on the co-occurrence frequencies of
   the items, that are then adjusted for different quantities. Examples
   include the cosine (the most popular one), the association strength
   (used in VOSviewer, see the Appendix), the inclusion index, and the
   Jaccard index (Eck and Waltman 2009). In the latter approach, the focus
   is on the way two items are related to all the other items in the
   dataset under study. This means that what is compared to obtain the
   similarity between two items are their entire profiles, i.e., the
   entire rows (or columns) of the co-occurrence matrix, and not their
   simple co-occurrence frequency. Pearson‚Äôs correlation coefficient (r),
   the cosine [11], and the chi-squared distance are examples of indirect
   similarity measure based on the global approach (McCain 1990; White and
   Griffith 1981). However, the reliability of Pearson‚Äôs r as a similarity
   measure has been contested (Ahlgren, Jarneving and Rousseau 2003; Eck
   and Waltman 2008).

   In general, there is no agreement on what the best normalization
   procedure is and on what similarity measures should be used in science
   mapping (Boyack and Klavans 2019; Leydesdorff 2008; Van Raan 2019). In
   the scientometric community, the discussion still goes on after 35
   years (e.g., Zhou and Leydesdorff 2016). However, it is important to
   remember that, depending on the chosen procedure, the resulting science
   maps can be rather different (Boyack, Klavans, and B√∂rner 2005).

                                                            [top of entry]

4.1.4 Visualization

   Visualization is the step in the science mapping process in which the
   information contained in the network is displayed in a visual layout
   comprehensible to human understanding. Following Waltman and van Eck
   (2014), we distinguish two basic types of visualizations: graph-based
   and distance-based. They are not the only approaches available but are
   probably the most common in science mapping [12].

   In graph-based visualization, the network is visualized as a graph made
   of nodes and edges (Fig. 1, 2, 3, 4, and 5 are examples of graph-based
   visualizations). The edges (links between nodes) are displayed to
   indicate the relatedness of nodes. The most common technique for
   creating such graphs are force-directed graph drawing algorithms, such
   as the Kamada and Kawai and the Fruchterman and Reingold (Chen 2013).

   To understand the underlying mechanism of these algorithms, imagine the
   network as a physical system, in which the nodes are little balls
   electrically charged and the links are springs that connect them. The
   electric charge creates a repulsive force between the balls,
   counterbalanced by the attractive force generated by the springs. The
   algorithms basically simulate the network as such a physical system
   made of balls and springs and apply two opposite forces to the nodes,
   one attractive (proportional to the weight of the link between two
   nodes) and the other repulsive, until the system comes to a state of
   mechanical equilibrium. The final layout is the one corresponding to
   such an equilibrium state. Note that several configurations are
   possible since usually there is no unique equilibrium state.

   Force-directed graph drawing algorithms are implemented in software for
   network analysis and visualization, such as Gephi [13] and Pajek [14].
   An example of a graph-based science map created with Pajek and
   visualized with the Kamada and Kawai algorithm can be found in
   (Leydesdorff and Rafols 2009, fig. 4). An example of a graph-based
   science map created with Gephi can be found in (Weingart 2015, fig. 4)

   The other visualization approach is distance-based. In distance-based
   visualizations, the distance of nodes on the map reflects their
   similarity, so that similar nodes are placed closer and dissimilar
   nodes far away. Note that in graph-based visualization, on the other
   hand, the position of the nodes is not directly related to their
   similarities, but it is a product of the ‚Äúpull and push‚Äù mechanism of
   the drawing algorithm. In distance-based visualizations, links can be
   shown or not.

   Distance-based visualizations are conceptually closer to geographic
   maps than graph-based visualizations. Geographic maps represent
   relationships in space by placing objects that are close in the
   physical space near on the maps and objects that are distant in the
   physical space further apart on the map. Distance-based maps have the
   same goals, but instead of being based on physical distances, they are
   based on similarities between objects.

   To produce a distance-based visualization, therefore, the similarities
   between the nodes must be transformed into distances [15]. The distance
   matrix that is thus obtained is conceptually analogous to the table
   reporting the distances between pairs of cities in a geographic atlas.
   The task consists of reconstructing from the relative distances the
   positions of the items on the map, i.e., in finding the coordinates of
   the items in a two-dimensional space starting from their reciprocal
   distances.

   To fulfill this task several statistical techniques have been
   developed. The most important belong to the family of multi-dimensional
   scaling (MDS) methods (Borg and Groenen 2010). They aim to find the
   coordinates of the points in a lower-dimensional space (usually, a
   plane) such that the distances of the points on the lower-dimensional
   space reflect as accurately as possible the original distances of the
   points. The average difference between the distances on the map and the
   original distances tells us how much the map distorts the original
   configuration. The amount of distortion is used to calculate the stress
   of the map. The various algorithms for MDS essentially adjust the
   positions of the points until a minimum value of stress is reached
   [16].

   It is important to underlie that distance-based visualizations can be
   rotated, flipped, and mirrored. Since the output of MDS is not a set of
   fixed coordinates but a set of relative distances between the points,
   any geometrical transformations that leave them unaltered can be
   applied. An example of distance-based visualization can be found in
   (White and McCain 1998, fig. 2).

   When interpreting the output of MDS, that is usually a two-dimensional
   map, is it very important to be aware that the algorithms can generate
   visual artifacts, i.e., structures or patterns that are visible on the
   map but that are not present in the original data. For instance, Eck
   and co-authors (2010) note that variants of MDS tend to produce
   quasi-circular layout when used on big matrices and that they tend to
   locate items with a high number of co-occurrences toward the center of
   the map.

   However, the trickiest artifacts have to do with the issue of
   dimensionality reduction, i.e. with the very core of MDS. Imagine that
   we have four points in a three-dimensional space, each one located at
   the same distance from the others, like the vertices of a three-sided
   pyramid, all sides of equal length (Borg and Groenen 2010, chap. 13.3).
   When we try to place the four points in a two-dimensional plane, we can
   respect the equal distance only for three points out of four. The
   fourth point will lie almost at the center of a bi-dimensional triangle
   (as if we were looking at the pyramid from the above) so that its
   distance from the other points will always be shorter than the
   distances between the three points themselves [17]. Without knowing the
   original three-dimensional structure and by looking only at the
   two-dimensional map, we would wrongly conclude that the fourth point is
   closer to the other three. The wrong conclusion raises from the fact
   that the two-dimensional map necessarily distorts the three-dimensional
   structure because it suppresses the third dimension, which however
   carries essential information (the equal distance between the fourth
   point and the other three points). By losing such information, it
   introduces an artifact. Interestingly, MDS can generate also the
   opposite artifact: points that are placed far away in the map can be
   however connected by ‚Äútunnels‚Äù in hidden dimensions (Leydesdorff and
   Rafols 2009). Imagine a paper sheet with two distant points on it: if
   we bend the sheet, we can make the two points very close in the third
   dimension, realizing a ‚Äútunnel‚Äù between them. If we consider only their
   distance on the two dimensions of the sheet, however, they will appear
   to be distant.

   In sum, dimensionality reduction techniques do allow us to obtain
   significant insights into the structure of bibliometric networks
   because they reveal the main features of such a structure. At the same
   time, since those features may lie in more than two dimensions, one
   must be aware of the inevitable distortions introduced by the
   dimensionality reduction itself.

                                                            [top of entry]

4.1.5 Enriching the map

   With the visualization of the network, we reach the basic form of the
   science map. At this point, the interpretation of the map can already
   begin. However, it is common to enrich the basic form by displaying
   further information on it.

   A first option is to use the size of the nodes and the width of the
   links to convey their properties. In a co-citation map, for instance,
   the size of the nodes can be used to represent the number of citations
   collected by the units of analysis (publication, journal, author, etc.)
   and the links can be drawn thicker or darker to express the strength of
   the connections (e.g., number of co-citations between two nodes).
   Alternatively, the size of the nodes can be used to represent the
   centrality of the nodes, using one of the different notions of
   centrality defined in network theory. The most common include degree
   centrality, betweenness centrality, closeness centrality, and
   eigenvector centrality (Wasserman and Faust 1994). The degree
   centrality of a node is proportional to the number of its links so that
   it is higher for highly connected nodes. Betweenness is a measure of
   brokerage of gatekeeping, that is of how much a node is an ‚Äúobligatory
   passage‚Äù in the network. In science mapping, it is sometimes used to
   measure interdisciplinarity (Leydesdorff 2007). Closeness measures how
   close a node is to the other nodes in the network. Nodes with high
   closeness are the ones that can be reached with few steps [18] from any
   other node in the network. Lastly, eigenvector centrality is a measure
   of the influence of a node in the network. The underlying idea of
   eigenvector centrality is that the influence of a node depends on the
   influence of the nodes to which it is connected, so that a node
   connected with other central nodes increases its centrality.

   A further option to enrich the map is to use colors to distinguish
   visually different clusters of nodes. Networks typically display an
   internal organization in clusters or communities, that is groups of
   highly interconnected nodes (Radicchi, Fortunato and Vespignani 2012).
   In distance-based visualizations, clusters result as sets of close
   points, separated from other clusters by blank space. The techniques of
   cluster analysis can be used to detect such communities. One common
   method is hierarchical agglomerative clustering (Chen 2013). All the
   units of the map (the nodes) begin alone in groups of size one, then,
   at each iteration of the clustering algorithm, similar groups are
   merged, until all the nodes belong to one super-cluster. A resolution
   parameter controls the granularity of the clustering, i.e., the size of
   the communities. Different agglomerative methods are characterized by
   the definition of distance between clusters they use and by the metric
   employed to calculate the distances (there are lots of options besides
   the familiar Euclidian distance). In single-linkage clustering, the
   distance between two clusters is set equal to the distance between
   their closest nodes. In complete-linkage clustering, on the other hand,
   it is equal to the distance between the most distant nodes in the two
   clusters. Lastly, in centroid linkage clustering, it is equal to the
   distance between the ‚Äúcenters‚Äù or average points (centroids) of the
   clusters. These clustering procedures, however, are only a small
   fraction of the available techniques and algorithms for clustering and
   community detection. In the last years, the techniques based on
   modularity, originally developed in physics, are becoming increasingly
   popular (Thijs 2019) [19].

   Clusters can be labelled automatically by extracting terms from the
   titles, abstracts, and keywords of the publications in the clusters
   (Chen 2006) (see Section 4.2.2: Co-word analysis based on automatically
   extracted terms). Each cluster is thus provided with a word-profile and
   its most relevant words can be superimposed on the map to facilitate
   the interpretation of the clusters (Chen, Ibekwe-SanJuan and Hou 2010).

   A last method for enriching the science map is to use the overlay
   (Rafols, Porter and Leydesdorff 2010). In science overlay maps, the
   results of the mapping are laid over a background, that can be, for
   instance, a global map of science. The background serves as a reference
   system that facilitates the interpretation of the results. For
   instance, the scientific output of a university can be overlaid on a
   global map of science to get an insight into the scientific coverage of
   the university or its impact (see Section 8: Science maps and science
   policy).

                                                            [top of entry]

4.2 Term-based maps

   Term-based science maps are used to extract and visualize the
   intellectual content of a corpus of publications based on the analysis
   of the terms associated with those publications (B√∂rner, Chen and
   Boyack 2005). These terms can be the keywords or descriptors of the
   publications, or they can be extracted automatically from titles and
   abstracts or even the full texts of articles. Term-based science maps
   allow to explore at a fine-grained level the intellectual content of
   publications since titles, abstracts, and keywords are meant to report
   the main topics, concepts, and results of scientific articles (He 1999;
   Van Raan and Tijssen 1993).

   An important advantage of term-based mapping compared to citation-based
   mapping is that it applies to fields characterized by the scarce
   presence of citations, such as applied research and technology (Callon
   et al. 1983).

   Depending on the method by which the terms characterizing a publication
   are extracted, we can distinguish two types of term-based maps. Classic
   co-word analysis, developed by Callon and colleagues, is based on
   human-assigned keywords. Natural language processing (NLP)-based
   co-word analysis, on the other hand, is based on terms that are
   automatically extracted from the texts by natural language processing
   techniques.

   Independently of the method, however, co-word analysis rests on some
   assumptions that have been contested. The main one is that words and
   terms have a stable meaning across fields and over time so that they
   can be used as reliable proxies of scientific concepts and ideas
   (Leydesdorff 1997). However, this assumption may be false, and
   historians of science have shown that the phenomenon of meaning-shift
   indeed occurs in science (Kuhn 2000). A possible reply to this
   criticism is that words in co-word analysis are not used as carriers of
   meaning but as simple links between texts (Courtial 1998). From an
   operative point of view, meaning shift can be avoided by restricting
   the time scope of the analysis to a relatively short period and
   semantically homogeneous areas (Mutschke and Quan-Haase 2001).

                                                            [top of entry]

4.2.1 Classic co-word analysis and the strategic diagrams

   The first term-based maps were developed in the 1980s by a team of
   sociologists of science based at the Centre de sociologie de
   l‚Äôinnovation at the √âcole des mines in Paris. They were designed to
   study the interaction between scientific knowledge and technological
   innovation, and, more generally, the relations between science and
   society (Callon et al. 1983). It is important to point out that the
   theoretical foundation of co-word analysis developed by Callon and
   others lies in the tradition of the science and technology studies, and
   in particular in the actor-network theory developed by Bruno Latour and
   others (Callon, Law and Rip 1998; Latour 2003). However, as a mapping
   method, co-word analysis can be employed without endorsing such a
   theoretical framework.

   Callon and colleagues focused in particular on the descriptors employed
   by documentation services to index the content of scientific and
   technological publications (Callon, Courtial and Laville 1991). The
   method of co-word analysis, then, consists first in collecting all the
   descriptors of the target documents. After a process of cleaning, in
   which variants and synonyms are merged and not relevant descriptors
   removed (see Section 3.3: Data cleaning and pre-processing), the
   co-occurrence frequency of each pair of descriptors is calculated. Two
   descriptors co-occur if they are used together in the description of a
   single document. A co-occurrence matrix reporting the co-occurrence
   frequencies of each pair of descriptors is thus produced, and the raw
   values are then normalized (see Section 4.1.3: Normalization).

   In the classic co-word methodology, as described by Callon and
   colleagues, the visualizations produced by co-word analysis are
   strategic diagrams (sometimes called cognitive maps), which are a
   special kind of science map that should not be confused with
   distance-based visualizations. To create a strategic diagram, clusters
   of frequently co-occurring descriptors or keywords are created by some
   clustering technique. Such clusters are called themes and are described
   by two characteristics: centrality and density. The centrality of a
   cluster is given by its external link, i.e., the number of links it has
   with other clusters. The density of a cluster is defined as the
   proportion between the links that are present in the keywords cluster
   and the number of possible links. Each theme is thus defined by two
   variables, centrality and density, that constitute its coordinates in
   the strategic diagram (He 1999). Then, the strategic diagram is divided
   into four quadrants (Mutschke and Quan-Haase 2001). The themes in the
   first quadrant are characterized by high density and high centrality
   and constitute the mainstream of the scientific field. The themes in
   the second quadrant, characterized by high centrality and low density,
   are unstructured themes that may be described as ‚Äúbandwagon‚Äù themes.
   The themes in the third quadrant are characterized by high density and
   low centrality: they have a well-developed maturity but lacks ties to
   other themes in the field. They are the ‚Äúivory tower‚Äù themes. Lastly,
   the themes in the fourth quadrant, characterized by low centrality and
   low density, comprise both topics that are fading away and new topics
   that are emerging. In longitudinal analysis, the trajectory of a theme
   can be followed through the quadrants of the strategic diagram. An
   example of a strategic diagram can be found in (Cobo et al. 2011a, fig.
   6).

   The method of co-word analysis based on descriptors or other kinds of
   keywords may suffer from the so-called ‚Äúindexer effect‚Äù (Law and
   Whittaker 1992). ‚Üí Indexing may reflect the prejudices or points of
   view of the human indexers and may be inconsistent between different
   indexers or change over time. The indexer effect is a problem common to
   all human-based classifications. The study of research classification
   systems reveals that they cannot be taken at face value as they are the
   result of complex disciplinary negotiations in which both intellectual
   and academic interests are involved [20].

                                                            [top of entry]

4.2.2 Co-word analysis based on automatically extracted terms

   The indexer effect can be partially avoided by recurring to the
   automatic extraction of terms from titles, abstracts, or even the full
   texts of articles. However, even if this method does not rely on the
   choices of an indexer, it is not free of human intervention. In fact,
   it shifts from the choices of the indexer to the choices of the authors
   of scientific publications, who decide what words should be included in
   the titles and abstracts. The issue of meaning shift, therefore, is not
   solved.

   NLP techniques are used to extract terms from the textual data (Taheo
   2018). In general, terms are n-grams, i.e., sequences of n items
   (usually words). A special category of n-grams are noun-phrases, i.e.,
   sequences that consist exclusively of nouns and adjectives and that end
   with a noun (e.g., text mining, network analysis). Algorithms for term
   detection usually comprise several steps: first, the text is split up
   into sentences and sentences split up into single words (tokenization),
   then so-called stop-words are removed (words such as ‚Äúand‚Äù, ‚Äúor‚Äù,
   etc.), and the remaining words are assigned to a part of speech, such
   as verb, noun, adjective, etc. (part-of-speech tagging). Noun-phrases
   are then identified, and, lastly, variants (e.g., plurals) are merged
   into one form. Once the list of noun-phrases is obtained, a fraction of
   them is retained. A common strategy is to select only the most relevant
   noun-phrases. It is important not to confuse relevance with frequency:
   frequency is a brute measure of the occurrences of a term, whereas
   relevance can be conceived as a measure of how specific a term is
   (Sp√§rck Jones 1972). To understand the difference between the two, take
   a term such as method. In the scientific literature, it is denoted by a
   high frequency; however, it is scarcely relevant to characterize a
   scientific article, since is occurs probably in most scientific
   articles. Knowing that an article contains the term method is a very
   thin indication of its content. Because of its being too generic,
   method therefore has a low relevance. A term such as cardiovascular, on
   the other hand, is less frequent than method but conveys more
   information about the specific topic of an article. Therefore, it has a
   high relevance. Relevance scores serve to discriminate generic from
   specific terms. A common metric used in text mining to calculate
   relevance scores is TF-IDF, short for ‚Äúterm frequency-inverse document
   frequency‚Äù (Salton and McGill 1983). The underlying idea is that the
   relevance of a term is proportional to its occurrences and inversely
   proportional to the number of documents in which it occurs. Terms that
   occur very frequently in a few documents will score higher on TF-IDF
   than terms that occur very frequently in most of the documents. From
   this basic idea, more refined metrics to calculate the TF-IDF have been
   developed (Thijs 2019).

   After the selection step, the number of documents in which each pair of
   terms appear is calculated and the corresponding co-occurrence matrix
   generated. The process is then the same as citation-based maps.
   Usually, the raw co-occurrence frequencies are normalized (see Section
   4.1.3: Normalization), and then the term map is obtained in the form of
   a distance- or graph-based visualization (see Section 4.1.4:
   Visualization). Further techniques, such as clustering, can be applied
   to enrich the map (see Section 4.1.5: Enriching the map). Note that
   term-based maps thus obtained are different from the strategic diagrams
   produced by classic co-word methodology. They represent the topics
   recurring in the set of publications analyzed, rather than the
   properties of their themes.

   An example of term-based map is shown in Fig. 7.

   Fig. 7: Example of term-based map (click to enlarge) Figure 7: Example
       of term-based map (click to enlarge). The field mapped is human
    geography. The nodes represent the most occurring terms in the field.
   Size of the nodes is proportional to the term‚Äôs occurrence. A link is
   drawn between two terms if they co-occur in the same title or abstract.
     The thickness of the link between two nodes is proportional to the
        number of co-occurrences of the terms. The color of the nodes
     corresponds to the cluster they are attributed to by the clustering
          algorithm. Nodes are positioned in the map based on their
   co-occurrences, so that terms frequently occurring together are closer
         on the map. The visualization was produced with VOSviewer.

                                                            [top of entry]

4.3 Other network-based maps

   Besides citation networks and term networks, several other networks can
   be used to generate science maps. In this section, we briefly present
   co-authorship networks and interlocking editorship networks.

                                                            [top of entry]

4.3.1 Co-authorship networks

   Co-authorship networks are science maps in which the nodes represent
   authors and the links the relation of co-authorship, i.e., the number
   of articles authored together by each pair of authors (Newman 2001).
   Since co-authorship usually implies a strong relationship of
   collaboration (Katz and Martin 1997; Liu et al. 2005), co-authorship
   networks are used to reconstruct and investigate the social networks of
   researchers, the so-called ‚Äúinvisible colleges‚Äù (Crane 1972). It must
   be remembered, however, that co-authorship is only a proxy of
   scientific collaboration and that some type of collaborative work
   occurring in research (e.g., the work of laboratory technicians) do not
   lead automatically to the authorship (Laudel 2002). More generally, the
   practice of authorship and the requirements for being awarded
   authorship varies in different areas (Larivi√®re et al. 2016). Further
   issues that complicate the interpretation of co-authorship data are
   ‚Äúghost‚Äù and ‚Äúhonorary‚Äù authorship, as well as the phenomenon of
   ‚Äúhyper-authorship‚Äù (Cronin 2001). Especially in bio-medical fields,
   there is evidence that sometimes scientists are included as co-authors
   of articles even if they did not contribute to the research process
   (‚Äúgift‚Äù or ‚Äúhonorary‚Äù authorship), while others are denied legitimately
   earned authorship (‚Äúghost‚Äù authorship) (Wislar et al. 2011). Honorary
   authorship can artificially inflate the relevance of some researchers
   in the co-authorship network, whereas the ghost authors remain simply
   invisible to standard co-authorship analysis. Furthermore, in some
   areas such as high-energy physics and again biomedicine, the last years
   have witnessed massive levels of co-authorship. Cronin has coined the
   term hyper-authorship to describe such a growing phenomenon of
   publications with hundreds, if not thousands of co-authors. For
   instance, in 2015, a publication in high-energy physics counted 5000
   co-authors. Hyper-authorship does not only challenge the standard
   conception of authorship but also raises several issues about
   responsibility and accountability, which have been widely discussed by
   editors of biomedical journals (see e.g., ICMJE 2019). The presence of
   hyper-authorship is an important factor that must be considered when a
   field is investigated by of co-authorship networks.

   In sum, co-authorship networks are useful tools to investigate
   scientific collaboration, but, since they are based on formal
   authorship, they should be interpreted in the light of detailed
   knowledge of the authorship practices of the area under investigation,
   taking into consideration also possible distortions due to ghost,
   honorary and hyper-authorship.

                                                            [top of entry]

4.3.2 Interlocking editorship networks

   Interlocking editorship is a method to map relationships between
   journals. Two journals are connected in the interlocking editorship
   network when they have at least one member of the editorial board in
   common (Baccini and Barabesi 2010). The editors of a scientific journal
   play a relevant role as ‚Äúgatekeepers‚Äù of scientific disciplines since
   they manage the peer review process and make the final decision on the
   publication of articles (Crane 1967). Therefore, interlocking
   editorship networks can be used to reveal groups of journals whose
   editors endorse similar policies. Interlocking editorship networks seem
   to be highly correlated with journal co-citation networks, showing that
   similar editorial policies may reflect similar intellectual approaches
   to the discipline (Baccini et al. 2019).

                                                            [top of entry]

4.4 Other types of science maps

   In a broader sense of the term, we can include into the category of
   science maps also other visual representations of science that are not
   directly based on networks of scientific publications or that integrate
   network data with other types of data. Maps based on the analysis of
   patents belong to the first category and geographic maps of science to
   the second.

                                                            [top of entry]

4.4.1 Maps based on patents data

   Several maps can be generated from the analysis of patents, which are
   especially interesting for studying the dynamics of technology systems
   and the interaction between science and technology (Jaffe and
   Trajtenberg 2002). A first kind of patent map is based on the patents‚Äô
   meta-data stored in patent databases. Patents, like publications, have
   several meta-data, such as the applications, the region where a patent
   is in force, the classification category, the application year, etc.
   Moreover, patents frequently include references to the scientific
   literature and other patents as well. All these meta-data can be used
   to generate networks of patents or networks of patent features
   (Federico et al. 2017). For instance, Boyack and Klavans created a map
   of patents based on the International Patent Classification (IPC). The
   map shows the relations between patents based on their
   co-classification: patents that are classified in the same category
   form clusters (Boyack and Klavans 2008). Other patent maps can be
   generated based on the citation network of patents, applying the
   equivalents of the direct linkage, bibliographic coupling, and
   co-citation methods to patents (Wartburg, Teichert and Rost 2005).
   Analyzing the references to scientific publications contained in
   patents allows tracing the links between scientific knowledge and
   technological applications (Meyer 2000), whereas, by studying the
   scientists that are both authors of scientific publications and
   inventors of patents, it is possible to map the overlap between
   scientific and technological literature (Murray 2002). In the last
   years, text-mining techniques (see Section 4.2.2: Co-word analysis
   based on automatically extracted terms) have increasingly been applied
   to patent mapping (Ranaei et al. 2019). These methods allow us to
   automatically extract keywords from patent documents and then built
   patent maps or term-maps of patents (Lee, Yoon and Park 2009; Tseng,
   Lin and Lin 2007).

                                                            [top of entry]

4.4.2 Geographic maps of science

   The science maps we presented so far focused on the abstract spaces of
   science, such as citation, term, and collaboration spaces. Classic
   science maps aim at visualizing patterns and trajectories occurring in
   these abstract dimensions. Science, however, is also a concrete
   activity occurring in specific places on our planet (Finnegan 2015). In
   fact, science is produced in geographic sites that are not equally
   distributed on the Earth but are concentrated in few, highly developed
   areas. From those sites, scientific knowledge travels, as publications
   and researchers move around the globe. Geographic maps of science aim
   at describing the spatial diffusion of scientific activities and the
   circulation of scientific knowledge in the geographic space. They are a
   key research topic in spatial scientometrics (Frenken, Hardeman and
   Hoekman 2009) and an important tool in the geography of science
   (Livingstone 2003). By showing the unequal spatial distribution of
   science and research in different countries, they offer interesting
   insights into the structure of the global research system (Wichmann
   Matthiessen, Winkel Schwarz and Find 2002).

   Geographic maps of science are created by locating on a geographic map,
   e.g., a map of the Earth, the nodes of the network we focus on. For
   instance, the authors of a co-authorship network can be placed on the
   map based on the coordinates of their research institutions. Or a
   network of cities collaborating in the production of scientific papers
   can be constructed and plotted on a map (Leydesdorff and Persson 2010).
   Or citation flows between universities can be geographically visualized
   (B√∂rner et al. 2006). The tool CiteSpace (see the Appendix) provides a
   specific utility to generate geographic maps of science.

                                                            [top of entry]

5. The representation of time in science mapping

   There are different options to include the dimension of time into
   science maps. A first option consists in longitudinal mapping (Cobo et
   al. 2011a; Petrovich and Buonomo 2018; Petrovich and Tolusso 2019):
   based on the publication year of the bibliographic records, subsets of
   publications belonging to different timespans are created and each of
   them is mapped separately. Note that any mapping technique can be used,
   from co-citation analysis to co-word analysis. Each map will represent
   a sort of ‚Äúphotograph‚Äù of the field under investigation in a certain
   timespan. The sequence of maps allows visualizing the temporal dynamics
   of the field. A second option consists in representing on the same map
   the trajectories of the units that change their relative position is
   subsequent maps (White and McCain 1998). A third option is animating
   the map: instead of a static visualization, a short movie is created
   interpolating the layouts of the network in different moments
   (Leydesdorff and Schank 2008).

   The first maps including the temporal dimension, however, used a
   timeline to represent time. Garfield called them ‚Äúhistoriographs‚Äù
   (Garfield 2004). In the timeline-based approach, each node of the
   network (classically, a publication in a citation network) is linked to
   a specific point in time (e.g., the publication year). The
   visualization, then, uses two dimensions: the vertical one is the
   timeline, whereas the horizontal one is used to represent the
   relatedness of the items (Waltman and van Eck 2014). The result is a
   citation network spread over a timeline. Garfield tested the validity
   of the historiographs as tools for reconstructing the history of
   science by comparing the narration of the discovery of the DNA written
   by Asimov with the historiograph based on the bibliographies of the
   corresponding publications (Garfield 1973). He found a good overlap
   between the two: the key events in the discovery according to Asimov
   appeared also in the historiograph.

   Alluvial maps are another form of timeline-based visualizations.
   Starting from different phases in the evolution of a network, the
   networks relative to each phase are divided into different clusters,
   and then the trajectories of corresponding clusters in subsequent
   networks are visualized as a stream. The fusions and fissions of
   clusters over time is visualized as multiple streams flow over time
   (Rosvall and Bergstrom 2010) [21].

   By combining co-citation mapping and temporal visualization, an amazing
   visualization of the temporal development of the journal Nature in the
   last 150 years was recently produced (Gates et al. 2019) [22].

                                                            [top of entry]

6. Interpreting a science map

   Interpreting a science map means linking the visual and geometrical
   properties of the map to substantive features of the mapped area or
   field. For instance, clusters of co-cited publications can be mapped to
   scientific sub-specialties or research topics, bibliographic coupling
   networks can be interpreted as the research fronts of scientific
   specialties, co-authorship networks as invisible colleges of
   scientists, and clusters of journals sharing many editors as structures
   of academic power. The interpretation of science maps typically
   involves close interaction with experts of the mapped domain, i.e.,
   experienced researchers that have a deep, albeit qualitative, knowledge
   of the structure of the target field (Tijssen 1993). Good science maps,
   however, should not be mere quantitative counterimages of the
   qualitative knowledge of the domain experts. They should provide also
   new insights and useful knowledge for science policy purposes.

   An important aspect to consider in the interpretation is the level of
   analysis of the science map, i.e., the units of analysis and the type
   of relationship displayed by the map. Units and relations do not only
   affect the scale of the map, but also the dimension of the scientific
   enterprise that is captured. Term-based maps and citation-based maps
   using the document as unit of analysis highlight the epistemic or
   cognitive dimension of science, what philosophers of science call the
   ‚Äúcontext of justification‚Äù (Lucio-Arias and Leydesdorff 2009). They
   show the shared epistemic base of a field (Persson 1994). However, they
   can overemphasize the stability of scientific knowledge, overshadowing
   the continuous social negotiation of scientific claims (Knorr-Cetina
   2003). Co-authorship maps. author co-citation analysis, and
   interlocking editorship maps, on the other hand, shed light on the
   social network underlying science, i.e., the ‚Äúcontext of discovery‚Äù in
   philosophical terms. When the journal is selected as unit of analysis,
   the communication system is highlighted (Cozzens 1989). Hence, the
   different methodologies of science mapping offer a partial
   representation of the multi-dimensional nature of science and
   scholarship, that should be considered during the interpretative phase.

   General theories and models of the structure and dynamics of science
   can also help in the interpretation of science maps, providing general
   interpretative insights (Boyack and Klavans 2019; Chen 2017;
   Scharnhorst, B√∂rner and Besselaar 2012). At the same time, however, it
   is pivotal to consider the specific academic and epistemic cultures of
   the field under study. The interpretation of a science map of a social
   scientific area, for instance, cannot be based on exactly the same
   concepts than the interpretation of a science map of a biomedical area,
   as the social sciences and biomedicine differ in terms of research
   methods, epistemic culture, specialized terminology, use of the
   references, centrality of the journal system, and so on.

   The humanities are a good case in point to highlight the importance of
   the specificity of research areas. Science mapping and, more generally,
   scientometrics and bibliometrics have mainly focused on the sciences
   since the times of Price and Garfield (Franssen and Wouters 2019).
   Bibliometric methods such as citation analysis were tailored to the
   citation norms and practices of the sciences. In the humanities,
   however, citations are frequently used not only to refer to other
   scholars‚Äô work but also to point out sources and primary materials, the
   equivalent of experimental data for the sciences (Hellqvist 2009).
   Negative or contradictory citations of the works of other scholars are
   relatively more common than in the sciences. In fields such as
   philosophy, where argumentation is the key epistemic practice, critical
   citations play a central role (Petrovich 2018). These field-specific
   citation practices must be considered in the interpretation of
   citation-based science maps of humanistic areas (Hammarfelt 2016).
   Moreover, publications in the humanities frequently do not target
   (only) fellow scholars, but also the wider public audience (Nederhof
   2006). This changes the level of specialized and standardized
   terminology used and, consequently, affect the capacity of term-based
   science maps to capture themes and topics [23]. To these interpretive
   caveats, one should add the limitations of the existing databases to
   adequately capture publications in the humanities, as they are often
   published as monographs and in national languages (Hammarfelt 2017).

                                                            [top of entry]

7. Science maps and the philosophy of science

   In this section, we deal with some epistemological and sociological
   topics related to science mapping. We start by asking in what sense
   science maps offer objective representations of science, then, we
   discuss the difference between the published side of science and
   science in the making, and, lastly, we examine in more detail the
   meaning of citations.

                                                            [top of entry]

7.1 On the objectivity of science maps

   Are science maps an objective representation of the structure and
   dynamics of science? Clearly, the answer greatly depends on the
   definition of objectivity we endorse (Daston and Galison 2007; Reiss
   and Sprenger 2017).

   In the previous sections, we saw how the creation of a science map
   involves several methodological and technical decisions from the
   science cartographer, such as the unit of analysis, the mapping
   technique, the normalization method, the visualization approach, the
   clustering algorithm, and so on (see Section 3: Building a science
   map). Each decision affects the results and lead to different science
   maps. Therefore, science maps, even when they are generated by computer
   software, should not be conceived as free of human intervention. Human
   choices occur frequently in the science map workflow and should be made
   transparent in order to warrant the reproducibility of science maps
   (Rafols, Porter and Leydesdorff 2010). Therefore, if we equate
   objectivity with the ‚Äúlack of human intervention‚Äù (the so-called
   mechanical objectivity), then science maps, like any other map, are not
   ‚Äúobjective‚Äù. Rather, they result from a combination of the features of
   the mapped field, on the one hand, and the methodological decisions of
   the science cartographer on the other hand. However, we should
   acknowledge that no map ‚Äî including geographic maps ‚Äî is ‚Äúobjective‚Äù in
   this sense. On the other hand, if objectivity is intended as
   inter-subjective agreement, then science maps are objective in so far
   as they can be reproduced by different researchers, as long as that
   they follow the same methodology.

   A further sense of objectivity has not to do with a lack of human
   interventions but a lack of human biases. According to some authors,
   science maps are more objective than classic literature reviews
   precisely in the sense that science maps would avoid the potential
   biases of human experts (e.g., Catherine and Doehne 2018; Kreuzman
   2001; Small and Griffith 1974; Weingart 2015). The idea is that the
   expert‚Äôs knowledge of a research field is inevitably constrained by his
   or her reading capacity: for how many papers one can read, they will
   always represent no more than a tiny portion of the literature
   available in most of the scientific fields. Even if such limitations
   can be mitigated by recurring to teamwork and by integrating the
   knowledge of many experts, the view of scientific fields that can be
   achieved in this way will always be partial. Thus, there is the
   potential risk that the representations of the scientific fields are
   distorted by the experts‚Äô viewpoint (if not prejudices). By contrast,
   the networks on which science maps are based are the result of millions
   of micro-actions performed by the scientific community itself, such as
   the choice of certain references or words. Science maps allow keeping
   track of this myriad of micro-actions. Consider for instance the
   bibliography of a research article. Since the authors cite other
   publications that are relevant to their work, the bibliography can be
   conceived as a (very partial) representation of the field to which the
   paper belongs. In so far as each new contribution must be related, by
   references, to the existing body of knowledge (the field), each paper
   can be compared to a mirror that reflects ‚Äî albeit partially ‚Äî the
   entire field (Amsterdamska and Leydesdorff 1989). It is a sort of
   ‚Äúphotograph‚Äù taken from a certain viewpoint. Hence, the aggregation of
   the bibliographies of thousands of articles that is performed to
   produce a citation-based map can be compared to the merging of
   thousands of partial photographs to make up a single, overall picture.
   In this aggregation process, different publications are related to one
   another ‚Äúunwittingly‚Äù by the scientific community itself. According to
   some authors, when enough large aggregates of publications are
   considered, the biases occurring in the individual bibliographies
   cancel out and a balanced picture is obtained (Van Raan 1998). The
   underlying assumption is that, at least on average, the citation
   behavior of scientists follows a normative model, i.e., that citations
   are given because of the scientific content of the cited reference and
   not because of non-scientific motives (see Section 7.3: The meaning of
   citations).

   By the same token, the networks of words visualized in term-based maps
   allow reconstructing the terminology of a scientific field because they
   reflect thousands of terminological micro-choices made by the
   researchers when drafting the titles and abstracts of their papers. The
   relations between the different terms are the results of these choices.
   Idiosyncratic and non-standard terminological would again choices
   cancel out when enough publications are considered.

   In sum, science maps would be more objective than classic reviews
   because they are the result of a bottom-up approach (Petrovich 2019b).
   Instead of the traditional top-down approach that can potentially
   introduce biases in the field representation, science maps allow to
   represent ‚Äúthe point of view of the scientific community on itself‚Äù
   (Small 1973; Small and Griffith 1974). Once again, science maps are not
   objective because free of human choices. Rather, they are objective
   because they are based on thousands of human (micro)choices. The key
   difference between these micro-choices and the decisions taken by the
   experts in the top-down approach lies in the large number of the
   former. It is such a large amount that potentially guarantees the
   cancelling out of the biases and, thus, a more balanced representation
   of scientific fields. Far from being the ‚Äúview from nowhere‚Äù on
   science, science maps are the collection of multiple, situated
   viewpoints on science.

   A last point about the objectivity of science maps is worth stressing:
   even if science maps provide bottom-up representations of science,
   nonetheless they remain partial from some points of view. First, a
   science map cannot represent more than what is contained in the data on
   which it is based. Since the scope of data depends on the scope of the
   bibliographic databases, science mapping techniques will deliver very
   partial representations for those scholarly fields that are scarcely
   covered by current databases, such as some areas in the social sciences
   and humanities or scholarly production in national languages (Franssen
   and Wouters 2019; Nederhof 2006). This does not mean that science maps
   provide false or distorted representations: rather that they ultimately
   depend on the scope and limits of the data on which they are generated.
   The second reason why science maps are partial is subtler, and it has
   to do with the nature of the bibliographic data and how they represent
   the scientific activity. We discuss this topic in the next paragraph.

                                                            [top of entry]

7.2 Published science vs. science in the making

   A defining trait of standard science maps is that they are generated
   based on the meta-data of scientific publications, as they are stored
   in bibliographic databases. However, publications (research articles,
   reviews, conference proceedings, patents, etc.) are only the final
   stage of a long and often rough research process. They are not meant
   and should not be considered as simple mirrors of the research
   practices themselves (Hyland and Salager-Meyer 2009; Wouters 1999a).
   The writing of a scientific paper involves the construction of a
   justificatory structure in which each experiment and analysis
   contribute to the justification of the paper‚Äôs claims (Gross et al.
   2002). As sociological and anthropological studies have revealed, real
   research practices can be a lot less smooth than the accounts we find
   in the scientific papers (Knorr-Cetina 2003; Latour and Woolgar 1986;
   Townsend and Burgess 2009). Real research is full of false starts,
   blind alleys, and mistakes. Discoveries may occur because of
   serendipity or intuition, the order of the experiments can be different
   both from the research plan and from the methodology described in the
   final paper, research targets may be affected by changes in funding,
   availability of materials and expertise, even academic circumstances.
   Moreover, scientific writing is a literary genre that follows precise
   rules, ranging from the format (e.g., the division of a research
   article into standard sections, such as Introduction, Methods, Results,
   and Discussion), to the writing style (in some fields, an impersonal
   style is recommended to increase the ‚Äúobjectivity‚Äù of the results)
   (Bazerman 1988; Hyland and Salager-Meyer 2009; Swales 2004). Journals‚Äô
   guidelines and peer-review reports can further affect the final form of
   a paper.

   Since standard science maps are based on the published side of science,
   they cannot be used to investigate any research practice that is not
   recorded in publications. Most of what Bruno Latour has called the
   ‚Äúscience-in-action‚Äù, thus, remains out of the reach of standard science
   mapping based on bibliographic databases. Note, however, that science
   mapping as a method can be potentially applied to any relational
   feature of the scientific enterprise. Other relational features,
   describing the science-in-action, could be mapped by new science
   mapping techniques (for instance, informal exchanges between scientists
   at scientific congresses, e-mail flows between laboratories, informal
   collaboration networks not resulting in co-authorship, etc.). However,
   new ad-hoc databases must be built to map these features, a costly and
   time-consuming enterprise (Boyack and Klavans 2019).

                                                            [top of entry]

7.3 The meaning of citations

   Citations are pivotal in science mapping: without the reference links
   connecting scientific publications, citation-based maps would be simply
   impossible. However, citations are a human product: they are the result
   of the choices made by the authors during the writing of their
   scientific papers. Why do scientists choose some references instead of
   others? Do they cite only because of the scientific merit of the cited
   works? How does the citation behavior of scientists change in different
   scientific fields? In traditional citation analysis and in standard
   science mapping, citations are treated equally, i.e., all have the same
   value. However, some cited papers are widely discussed, while others
   are perfunctorily cited. Some papers are even negatively cited. How can
   we capture the different functions and values of citations?

   Questions like these are discussed in scientometrics and sociology of
   science under the label of citation theory (Bornmann and Daniel 2008;
   Cronin 1984; Wouters 1999b). Most of them are discussed since the dawn
   of citation analysis and still do not have received definite answers. A
   complete overview of citation theories is out of the scope of the
   present article [24]. In this section, we will limit to present the two
   main approaches, in so far as they can help to interpret and
   contextualize the results of science mapping: the normative theory and
   the socio-constructivist theory.

   The normative theory was proposed within the framework of the normative
   sociology of science developed by Robert K. Merton and his school from
   the 1960s (Elkana et al. 1978; Kaplan 1965; Merton 1974). According to
   this theory, scientists cite to pay their intellectual debts: when they
   use the results obtained by other scientists in their research, the
   norms of science demand them to acknowledge the debt by explicitly
   citing the relevant papers. Citations count as ‚Äúpellets of peer
   recognition‚Äù and play a fundamental role in the reward system of
   science: they serve to distribute prestige among scientists. An
   important consequence of the normative theory is that citations can be
   considered as reliable proxies of scientific quality or impact. Thus,
   the normative theory provides a theoretical justification for the use
   of citations in evaluative contexts. However, the main claim of the
   normative theory (i.e., that the citation reflects the scientific merit
   of the cited document, author, or journal) rests upon several
   assumptions, e.g., that citations are made to the best possible works,
   that all citations have equal weight, and that the citation of a
   document implies the use of the document by the citing author
   (Nicolaisen 2007). Both the main claim and the underlying assumptions
   have been criticized.

   The socio-constructivist approach to citations is grounded in the
   socio-constructivist sociology of science, a sociological paradigm that
   raised in different forms in the 1970s partly as a reaction to the
   normative school (Bloor 1991; Knorr-Cetina 2003; Latour 2003).
   According to socio-constructivists, scientific facts are the result of
   an intricate process of social negotiation among different actors. In
   the social arena of science, scientists use any means necessary to
   advance their claims and achieve a high status in the scientific
   community. No normative system, such as the one described by Merton,
   governs their actions. Socio-constructivists maintain that citations
   play a key role in the social negotiation of scientific facts. In
   particular, they are used as means of persuasion: scientists trade on
   the authority of the cited authors to strengthen their claims.
   Citations are rhetorical devices that can be compared to ‚Äúdefense
   lines‚Äù prepared by the scientists to defend their results from
   criticisms of adversary scientists. Socio-constructivists note also
   that scientists often distort the content of the documents they cite,
   in order to show agreement with authoritative sources even when no such
   an agreement exists. The reason is that scientists would be more
   interested in who they cite, rather than in what the cited documents
   say. Citations, therefore, would reflect the social dynamics of the
   scientific community, rather than the accumulation of scientific
   knowledge. An important consequence is that they cannot be used as
   proxies of scientific quality (MacRoberts and MacRoberts 2018).

   Empirical research has shown that neither the normative nor the
   socio-constructivist theory offer, alone, complete explanations of the
   citation behavior of scientists. The motivations for citing are complex
   and multi-dimensional: sometimes they reflect purely scientific
   reasons, as the normative theory holds, and sometimes obey to
   social-networking purposes, as the socio-constructivist theory holds
   (Tahamtan and Bornmann 2018). Besides the motivations of scientists,
   also the characteristics of the communication system of science
   (journals, publishers, and so on) affect the probability of receiving
   citations (Cozzens 1989). For instance, publications in languages
   different from English tend to receive, on average, fewer citations,
   whereas review articles tend to attract more citations than research
   articles (Bornmann and Daniel 2008). The citation links between
   documents and authors, therefore, are affected by many different
   factors, of which scientific merit is only one.

   When interpreting the results of citation-based science mapping, we
   should not overlook the complexity of the citation practices that
   determine the links in the citation network. An understanding of the
   ‚Äúcitation culture‚Äù (Wouters 1999a) of the mapped field helps to
   interpret correctly a science map.

                                                            [top of entry]

8. Science maps and science policy

   Since the first experiments in science mapping in the 1970s, science
   maps have been presented recurrently as helpful devices for science
   policy and research management. The idea is that, since science maps
   offer a panoramic viewpoint of the research landscape, they can also
   help to navigate it. Science maps would offer for the abstract space of
   science the same service of orientation that geographic maps provide
   for the physical space (Small 1999).

   Possible science policy topics that can be addressed with the help of
   science maps include (Boyack, Klavans and B√∂rner 2005; Rafols, Porter
   and Leydesdorff 2010):
    1. Benchmarking: How is an organization performing compared to
       competitors?
    2. Collaboration strategy: Who are the potential collaborators that
       can complement the research mission of the organization?
    3. Development analysis: How do the research themes of an organization
       develop over time?
    4. ‚ÄúHot areas‚Äù detection: What are the scientific areas that are
       growing faster? What is their potential for technological transfer?

   One important advantage of science maps compared to classic reviews is
   that they allow also the non-experts to grasp easily and quickly the
   main features of a scientific field because they rely on the
   recognition of visual patterns rather than on deep scientific
   expertise. Therefore, they can be used as a common base between
   researchers, science managers, analysts, and policymakers to discuss
   strategic decisions, such as the allocation of resources (B√∂rner et al.
   2012; Noyons and Calero-Medina 2009).

   Nonetheless, science maps should be used in science policy contexts
   with a clear understanding of their limits: science maps can help the
   decision-making, but they do not provide automatic answers. From this
   point of view, science maps are not different from any scientometric
   indicator: they provide partial representations of science whose
   correct interpretation should take into account many different factors
   (see Section 7.1: On the objectivity of science maps) [25]. Not only
   science maps are error-prone (e.g., if they are generated based on an
   incorrect field delineation procedure, see Section 3.2: Field
   delineation), but, as we saw above, their production involves several
   technical decisions that can deeply influence the final maps (see
   Section 4.1.3: Normalization and Section 4.1.4: Visualization). It is
   pivotal that such decisions should be made transparent, and their
   consequences clear to the analysts and the policymakers, so that
   science maps do not turn into ‚Äúblack boxes‚Äù (Rafols, Porter and
   Leydesdorff 2010).

   Fortunately, science maps are usually perceived as more complex
   objects, compared to mono-dimensional scientometric indicators such as
   citation counts or the Journal Impact Factor. Thus, they tend to
   stimulate a higher level of reflexivity in their users compared to
   sheer numbers. Such reflexivity should always be preserved in science
   policy contexts, where science maps must not be treated as ‚Äúoracles‚Äù,
   even when science politicians and research managers desire simple and
   straightforward answers. When using science maps, it must be remembered
   that science is a complex system, where simple, ready-made answers can
   be given very rarely.

                                                            [top of entry]

9. Conclusion

   In this entry, we have seen how the visual representation of science by
   science maps takes different forms, depending on the kind of data, the
   unit of analysis, the type of relation examined, and the overall
   mapping approach used. A science map can take both the form of a
   bibliometric network and that of a geographic map or of a patent map.
   Even artistic representations of the sciences have been called, in a
   derivate way, ‚Äúscience maps‚Äù (B√∂rner 2010). Science maps find
   application in different domains, from sociology of science to science
   policy, from scientometrics to information visualization. As we have
   seen, science mapping, as a body of techniques, stands at the crossroad
   of numerous disciplines: scientometrics, ‚Üí library and information
   science, citation analysis, text analysis, statistics, network
   analysis, among others.

   Given this manifold of methods, disciplines, and uses, it is difficult
   to find a common trait that identifies the uniqueness of science
   mapping. Perhaps, what most if not all science maps share is a
   bottom-up approach to the investigation of the structure and dynamics
   of science (Petrovich 2019b). Compared with top-down KOSs, science maps
   aim at representing science starting from the scientific products
   themselves rather than from more or less a priori conceptual schemes.
   In this sense, they may capture those structuration forces that shape
   the overall configuration of the scientific system and that may remain
   invisible to top-down KOSs. Science mapping may be valuable to shed
   light on the self-organizing properties of the scientific enterprise
   (Lucio-Arias and Leydesdorff 2009). Hence, we think that science maps
   can be of interest for all the branches of meta-science, from library
   and information science to sociology of science, from knowledge
   organization to epistemology.

                                                            [top of entry]

Acknowledgments

   I am grateful to Alberto Baccini, Emiliano Tolusso, two anonymous
   reviewers, and the editor for helpful comments and suggestions on a
   previous version of this entry. I gratefully acknowledge financial
   support from the Institute for New Economic Thinking (INET) under grant
   n. INO19-00023.

                                                            [top of entry]

Endnotes

   1. http://scimaps.org/home.html.

   2. https://en.wikipedia.org/wiki/Liberal_arts_education#/media/
   File:Hortus_Deliciarum,_Die_Philosophie_mit_den_sieben_freien_K%C3%BCns
   ten.JPG.

   3. Numerous examples of classifications and visual representations of
   the sciences over the centuries can be found and explored in the
   Interactive Atlas of the Disciplines
   (http://atlas-disciplines.unige.ch/).

   4. A detailed timeline with key milestones in science mapping history
   can be found in the Part 2 of B√∂rner (2010).

   5. https://academic.microsoft.com/.

   6. https://www.dimensions.ai/.

   7. https://www.uspto.gov/.

   8. http://www.google.com/patents.

   9. http://www.epo.org/patents/patent-information.html.

   10. This is the adjacency matrix we obtain when we consider the network
   as directed, i.e., when we distinguish between the sender and the
   receiver of the citation. It is also possible to consider the citation
   network as undirected. In this case, the elements of the matrix will be
   set to 1 when there is a link between the publications, independently
   whether it is a citation (in-coming link) or a reference (out-going
   link), obtaining a symmetrical matrix:

       a b c d e f g h
     a 0 1 1 1 1 0 0 0
     b 1 0 1 0 0 0 0 1
     c 1 1 0 0 1 1 1 0
     d 1 0 0 0 0 0 1 0
     e 1 0 1 0 0 0 1 0
     f 0 0 1 0 0 0 1 0
     g 0 0 1 1 1 1 0 0
     h 0 1 0 0 0 0 0 0

   11. Note that there are two different similarity measures, a direct and
   an indirect, both called ‚Äúcosine‚Äù. The indirect cosine ‚Äî that
   corresponds to the original cosine introduce by Salton and McGill
   (Salton and McGill 1983) ‚Äî is based on the angular distance between two
   vectors and it is calculated from the inner product of the vectors
   (Jones and Furnas 1987). The direct cosine is a simplified version of
   the indirect cosine and it corresponds to a variant of the Ochiai
   coefficient (Zhou and Leydesdorff 2016).

   12. An interesting alternative visualization, closely modelled on
   geographic maps, is based on the so-called self-organizing maps (SOM).
   We refer to Skupin, Biberstine and B√∂rner (2013) for a detailed
   explanation of this technically advanced visualization method.

   13. https://gephi.org/

   14. http://mrvar.fdv.uni-lj.si/pajek/.

   15. Note that not all the similarity measures fulfill the requirements
   of a distance metric. For instance, negative similarity measures (such
   as the ones produced by Pearson‚Äôs r) cannot be used as distances
   because a negative distance is meaningless. The other conditions to be
   satisfied are that the distance of an object from itself should be
   zero, that the distance between A and B should be equal to the distance
   between B and A (symmetry), and that the distance from A to B is at
   most as large as the sum of the distance from A to C and the distance
   from C to B (triangle inequality).

   16. A technical but very clear explanation of MDS can be found in Borg
   and Groenen (2010, chaps 1‚Äì3) and in Eck et al. (2010).

   17. It is easy to see that it is a consequence of the triangle
   inequality mentioned in the note above.

   18. More precisely, shortest paths.

   19. Hennig et al. (2016) offers an overview and technical discussion of
   clustering techniques.

   20. From this point of view, the history of the JEL codes used in
   economics is very instructive (Cherrier 2017).

   21. A tool for generating alluvial maps starting from network data is
   available at https://www.mapequation.org/alluvial/.

   22. The map can be explored at
   https://www.nature.com/immersive/d41586-019-03165-4/. A video
   explaining the structure of the map is available at
   https://www.youtube.com/watch?v=GW4s58u8PZo.

   23. I am grateful to an anonymous reviewer for pointing me out this
   difference in the use of specific terminology between the sciences and
   humanities.

   24. See Tahamtan and Bornmann (2018; 2019) for an updated overview and
   Petrovich (2019a) for a systematization of the different theories.

   25. As it is well known, the use of scientometrics for evaluative
   purpose is a controversial topic that continue to raise heated
   discussions among researchers and policy makers. The presentation of
   this topic, however, falls beyond the scope of this article. See
   Aksnes, Langfeldt, and Wouters (2019) for an introduction.

                                                            [top of entry]

References

   Ahlgren, Per, Bo Jarneving, and Ronald Rousseau. 2003. ‚ÄòRequirements
   for a Cocitation Similarity Measure, with Special Reference to
   Pearson‚Äôs Correlation Coefficient‚Äô. Journal of the American Society for
   Information Science and Technology 54 no. 6: 550‚Äì60.
   https://doi.org/10.1002/asi.10242.

   Aksnes, Dag W., Liv Langfeldt, and Paul Wouters. 2019. ‚ÄòCitations,
   Citation Indicators, and Research Quality: An Overview of Basic
   Concepts and Theories‚Äô. SAGE Open 9 no. 1: 215824401982957.
   https://doi.org/10.1177/2158244019829575.

   Amsterdamska, Olga, and L. Leydesdorff. 1989. ‚ÄòCitations: Indicators of
   Significance?‚Äô Scientometrics 15 no. 5‚Äì6: 449‚Äì71.
   https://doi.org/10.1007/BF02017065.

   Ara√∫jo, Paula Carina de, Renata Cristina Gutierres Castanha and Birger
   Hj√∏rland. 2020. ‚ÄúCitation Indexing and Indexes‚Äù. Knowledge
   Organization, in press. Also available in ISKO Encyclopedia of
   Knowledge Organization, eds. Birger Hj√∏rland and Claudio Gnoli,
   https://www.isko.org/cyclo/citation.

   √Östr√∂m, Fredrik, Bj√∂rn Hammarfelt, and Joachim Hansson. 2017.
   ‚ÄòScientific Publications as Boundary Objects: Theorising the
   Intersection of Classification and Research Evaluation‚Äô. Information
   Research 22 no. 1: colis1623.
   http://informationr.net/ir/22-1/colis/colis1623.html.

   Baccini, Alberto, and Lucio Barabesi. 2010. ‚ÄòInterlocking Editorship. A
   Network Analysis of the Links between Economic Journals‚Äô.
   Scientometrics 82 no. 2: 365‚Äì89.
   https://doi.org/10.1007/s11192-009-0053-7.

   Baccini, Alberto, Lucio Barabesi, Yves Gingras, and Mahdi Kalfaoui.
   2019. ‚ÄòIntellectual and Social Similarity among Scholarly Journals: An
   Exploratory Comparison of the Networks of Editors, Authors and
   Co-Citations‚Äô.

   Barab√°si, Albert-L√°szl√≥. 2014. Linked: How Everything Is Connected to
   Everything Else and What It Means for Business, Science, and Everyday
   Life. New York: Basic Books.

   Bazerman, Charles. 1988. Shaping Written Knowledge: The Genre and
   Activity of the Experimental Article in Science. Rhetoric of the Human
   Sciences. Madison, Wis.: University of Wisconsin Press.

   Bloor, David. 1991. Knowledge and Social Imagery. 2nd ed. Chicago:
   University of Chicago Press.

   Borg, Ingwer, and Patrick J. F Groenen. 2010. Modern Multidimensional
   Scaling: Theory and Applications. New York; London: Springer.

   B√∂rner, Katy. 2010. Atlas of Science: Visualizing What We Know.
   Cambridge, Mass.: MIT Press.

   B√∂rner, Katy, Chaomei Chen, and Kevin W. Boyack. 2005. ‚ÄòVisualizing
   Knowledge Domains‚Äô. Annual Review of Information Science and Technology
   37 no. 1: 179‚Äì255. https://doi.org/10.1002/aris.1440370106.

   B√∂rner, Katy, Richard Klavans, Michael Patek, Angela M. Zoss, Joseph R.
   Biberstine, Robert P. Light, Vincent Larivi√®re, and Kevin W. Boyack.
   2012. ‚ÄòDesign and Update of a Classification System: The UCSD Map of
   Science‚Äô. Edited by Neil R. Smalheiser. PLoS ONE 7 no. 7: e39464.
   https://doi.org/10.1371/journal.pone.0039464.

   B√∂rner, Katy, Shashikant Penumarthy, Mark Meiss, and Weimao Ke. 2006.
   ‚ÄòMapping the Diffusion of Scholarly Knowledge among Major U.S. Research
   Institutions‚Äô. Scientometrics 68 no. 3: 415‚Äì26.
   https://doi.org/10.1007/s11192-006-0120-2.

   B√∂rner, Katy, Todd N. Theriault, and Kevin W. Boyack. 2015. ‚ÄòMapping
   Science Introduction: Past, Present and Future: Mapping Science
   Introduction: Past, Present and Future‚Äô. Bulletin of the Association
   for Information Science and Technology 41 no. 2: 12‚Äì16.
   https://doi.org/10.1002/bult.2015.1720410205.

   Bornmann, Lutz, and Hans-Dieter Daniel. 2008. ‚ÄòWhat Do Citation Counts
   Measure? A Review of Studies on Citing Behavior‚Äô. Journal of
   Documentation 64 no. 1: 45‚Äì80.
   https://doi.org/10.1108/00220410810844150.

   Boyack, Kevin W., and Richard Klavans. 2008. ‚ÄòMeasuring
   Science‚ÄìTechnology Interaction Using Rare Inventor‚ÄìAuthor Names‚Äô.
   Journal of Informetrics 2 no. 3: 173‚Äì82.
   https://doi.org/10.1016/j.joi.2008.03.001.

   Boyack, Kevin W., and Richard Klavans. 2010. ‚ÄòCo-Citation Analysis,
   Bibliographic Coupling, and Direct Citation: Which Citation Approach
   Represents the Research Front Most Accurately?‚Äô Journal of the American
   Society for Information Science and Technology 61 no. 12: 2389‚Äì2404.
   https://doi.org/10.1002/asi.21419.

   Boyack, Kevin W., and Richard Klavans. 2019. ‚ÄòCreation and Analysis of
   Large-Scale Bibliometric Networks‚Äô. In Springer Handbook of Science and
   Technology Indicators, edited by Wolfgang Gl√§nzel, Henk F. Moed, Ulrich
   Schmoch, and Mike Thelwall, 187‚Äì212. Springer Handbooks. Cham: Springer
   International Publishing. https://doi.org/10.1007/978-3-030-02511-3_8.

   Boyack, Kevin W., Richard Klavans, and Katy B√∂rner. 2005. ‚ÄòMapping the
   Backbone of Science‚Äô. Scientometrics 64 no. 3: 351‚Äì74.
   https://doi.org/10.1007/s11192-005-0255-6.

   Callon, Michel, J. P. Courtial, and F. Laville. 1991. ‚ÄòCo-Word Analysis
   as a Tool for Describing the Network of Interactions between Basic and
   Technological Research: The Case of Polymer Chemsitry‚Äô. Scientometrics
   22 no. 1: 155‚Äì205. https://doi.org/10.1007/BF02019280.

   Callon, Michel, J.-P. Courtial, W. A. Turner, and S. Bauin. 1983. ‚ÄòFrom
   Translations to Problematic Networks: An Introduction to Co-Word
   Analysis‚Äô. Social Science Information 22 no. 2: 191‚Äì235.
   https://doi.org/10.1177/053901883022002003.

   Callon, Michel, John Law, and Arie Rip, eds. 1998. Mapping the Dynamics
   of Science and Technology: Sociology of Science in the Real World.
   Transferred to digital printing. Houndmills: Macmillan.

   Catherine, Herfeld, and Malte Doehne. 2018. ‚ÄòFive Reasons for the Use
   of Network Analysis in the History of Economics‚Äô. Journal of Economic
   Methodology 25 no. 4: 311‚Äì28.
   https://doi.org/10.1080/1350178X.2018.1529172.

   Chen, Chaomei. 2006. ‚ÄòCiteSpace II: Detecting and Visualizing Emerging
   Trends and Transient Patterns in Scientific Literature‚Äô. Journal of the
   American Society for Information Science and Technology 57 no. 3:
   359‚Äì77. https://doi.org/10.1002/asi.20317.

   Chen, Chaomei. 2013. Mapping Scientific Frontiers: The Quest for
   Knowledge Visualization. Second Edition. London: Springer.

   Chen, Chaomei. 2017. ‚ÄòScience Mapping: A Systematic Review of the
   Literature‚Äô. Journal of Data and Information Science 2 no. 2: 1‚Äì40.
   https://doi.org/10.1515/jdis-2017-0006.

   Chen, Chaomei, Fidelia Ibekwe-SanJuan, and Jianhua Hou. 2010. ‚ÄòThe
   Structure and Dynamics of Cocitation Clusters: A Multiple-Perspective
   Cocitation Analysis‚Äô. Journal of the American Society for Information
   Science and Technology 61 no. 7: 1386‚Äì1409.
   https://doi.org/10.1002/asi.21309.

   Cherrier, Beatrice. 2017. ‚ÄòClassifying Economics: A History of the JEL
   Codes‚Äô. Journal of Economic Literature 55 no. 2: 545‚Äì79.
   https://doi.org/10.1257/jel.20151296.

   Cobo, M.J., A.G. L√≥pez-Herrera, E. Herrera-Viedma, and F. Herrera.
   2011a. ‚ÄòAn Approach for Detecting, Quantifying, and Visualizing the
   Evolution of a Research Field: A Practical Application to the Fuzzy
   Sets Theory Field‚Äô. Journal of Informetrics 5 no. 1: 146‚Äì66.
   https://doi.org/10.1016/j.joi.2010.10.002.

   Cobo, M.J., A.G. L√≥pez-Herrera, E. Herrera-Viedma, and F. Herrera.
   2011b. ‚ÄòScience Mapping Software Tools: Review, Analysis, and
   Cooperative Study among Tools‚Äô. Journal of the American Society for
   Information Science and Technology 62 no. 7: 1382‚Äì1402.
   https://doi.org/10.1002/asi.21525.

   Courtial, J. P. 1998. ‚ÄòComments on Leydesdorff‚Äôs Article‚Äô. Journal of
   the American Society for Information Science 49 no. 1: 98.

   Cozzens, Susan E. 1989. ‚ÄòWhat Do Citations Count? The Rhetoric-First
   Model‚Äô. Scientometrics 15 no. 5‚Äì6: 437‚Äì47.
   https://doi.org/10.1007/BF02017064.

   Crane, Diana. 1967. ‚ÄòThe Gatekeepers of Science: Some Factors Affecting
   the Selection of Articles for Scientific Journals‚Äô. The American
   Sociologist 2 no. 4: 195‚Äì201.

   Crane, Diana. 1972. Invisible Colleges; Diffusion of Knowledge in
   Scientific Communities. Chicago: University of Chicago Press.

   Cronin, Blaise. 1984. The Citation Process: The Role and Significance
   of Citations in Scientific Communication. London: T. Graham.

   Cronin, Blaise. 2001. ‚ÄòHyperauthorship: A Postmodern Perversion or
   Evidence of a Structural Shift in Scholarly Communication Practices?‚Äô
   Journal of the American Society for Information Science and Technology
   52 no. 7: 558‚Äì69. https://doi.org/10.1002/asi.1097.

   Daston, Lorraine, and Peter Galison. 2007. Objectivity. New
   York-Cambridge, Mass.: Zone Books; Distributed by the MIT Press.

   Eck, Nees Jan van, and Ludo Waltman. 2008. ‚ÄòAppropriate Similarity
   Measures for Author Co-citation Analysis‚Äô. Journal of the American
   Society for Information Science and Technology 59 no. 10: 1653‚Äì61.
   https://doi.org/10.1002/asi.20872.

   Eck, Nees Jan van, and Ludo Waltman. 2009. ‚ÄòHow to Normalize
   Cooccurrence Data? An Analysis of Some Well-Known Similarity Measures‚Äô.
   Journal of the American Society for Information Science and Technology
   60 no. 8: 1635‚Äì51. https://doi.org/10.1002/asi.21075.

   Eck, Nees Jan van, and Ludo Waltman. 2010. ‚ÄòSoftware Survey: VOSviewer,
   a Computer Program for Bibliometric Mapping‚Äô. Scientometrics 84 no. 2:
   523‚Äì38. https://doi.org/10.1007/s11192-009-0146-3.

   Eck, Nees Jan van, Ludo Waltman, Rommert Dekker, and Jan van den Berg.
   2010. ‚ÄòA Comparison of Two Techniques for Bibliometric Mapping:
   Multidimensional Scaling and VOS‚Äô. Journal of the American Society for
   Information Science and Technology 61 no. 12: 2405‚Äì16.
   https://doi.org/10.1002/asi.21421.

   Elkana, Yehuda, Joshua Laderberg, Robert K. Merton, Arnold Thackray,
   and Harriet Zuckerman, eds. 1978. Toward a Metric of Science: The
   Advent of Science Indicators. Science, Culture, and Society. New York:
   Wiley.

   Federico, Paolo, Florian Heimerl, Steffen Koch, and Silvia Miksch.
   2017. ‚ÄòA Survey on Visual Approaches for Analyzing Scientific
   Literature and Patents‚Äô. IEEE Transactions on Visualization and
   Computer Graphics 23 no. 9: 2179‚Äì98.
   https://doi.org/10.1109/TVCG.2016.2610422.

   Finnegan, Diarmid. 2015. ‚ÄòScience, Geography Of‚Äô. In International
   Encyclopedia of the Social & Behavioral Sciences, 21:236‚Äì40.

   Franssen, Thomas, and Paul Wouters. 2019. ‚ÄòScience and Its Significant
   Other: Representing the Humanities in Bibliometric Scholarship‚Äô.
   Journal of the Association for Information Science and Technology,
   March. https://doi.org/10.1002/asi.24206.

   Frenken, Koen, Sjoerd Hardeman, and Jarno Hoekman. 2009. ‚ÄòSpatial
   Scientometrics: Towards a Cumulative Research Program‚Äô. Journal of
   Informetrics 3 no. 3: 222‚Äì32.
   https://doi.org/10.1016/j.joi.2009.03.005.

   Garfield, Eugene. 1973. ‚ÄòHistoriographs, Librarianship, and the History
   of Science‚Äô. In Toward a Theory of Librarianship, edited by Conrad H.
   Rawski, 380‚Äì402. Metuchen, NJ: Scarecrow Press.

   Garfield, Eugene. 2004. ‚ÄòHistoriographic Mapping of Knowledge Domains
   Literature‚Äô. Journal of Information Science 30 no. 2: 119‚Äì45.
   https://doi.org/10.1177/0165551504042802.

   Gates, Alexander J., Qing Ke, Onur Varol, and Albert-L√°szl√≥ Barab√°si.
   2019. ‚ÄòNature‚Äôs Reach: Narrow Work Has Broad Impact‚Äô. Nature 575 no.
   7781: 32‚Äì34. https://doi.org/10.1038/d41586-019-03308-7.

   Gl√§nzel, Wolfgang. 2001. ‚ÄòNational Characteristics in International
   Scientific Co-Authorship Relations‚Äô. Scientometrics 51 no. 1: 69‚Äì115.
   https://doi.org/10.1023/A:1010512628145.

   Gross, Alan G., Alan G. Gross, Joseph E. Harmon, and Michael S. Reidy.
   2002. Communicating Science: The Scientific Article from the 17th
   Century to the Present. Oxford-New York: Oxford University Press.

   Hammarfelt, Bj√∂rn. 2016. ‚ÄòBeyond Coverage: Toward a Bibliometrics for
   the Humanities‚Äô. In Research Assessment in the Humanities, edited by
   Michael Ochsner, Sven E Hug, and Hans-Dieter Daniel, 115‚Äì31. Springer.

   Hammarfelt, Bj√∂rn. 2017. ‚ÄòFour Claims on Research Assessment and Metric
   Use in the Humanities‚Äô. Bulletin of the Association for Information
   Science and Technology 43 no. 5: 33‚Äì38.

   Harzing, Anne-Wil. 2019. ‚ÄòTwo New Kids on the Block: How Do Crossref
   and Dimensions Compare with Google Scholar, Microsoft Academic, Scopus
   and the Web of Science?‚Äô Scientometrics 120 no. 1: 341‚Äì49.
   https://doi.org/10.1007/s11192-019-03114-y.

   He, Qin. 1999. ‚ÄòKnowledge Discovery through Co-Word Analysis‚Äô. Library
   Trends 48 no. 1: 133.

   Hellqvist, Bj√∂rn. 2009. ‚ÄòReferencing in the Humanities and Its
   Implications for Citation Analysis‚Äô. Journal of the American Society
   for Information Science and Technology 61 no. 2: 310-318.
   https://doi.org/10.1002/asi.21256.

   Hennig, Christian M., Marina Meila, Fionn Murtagh, and Roberto Rocci,
   eds. 2016. Handbook of Cluster Analysis. Chapman & Hall/CRC Handbooks
   of Modern Statistical Methods 9. Boca Raton: CRC Press, Taylor &
   Francis Group.

   Hj√∏rland, Birger. 2013. ‚ÄòCitation Analysis: A Social and Dynamic
   Approach to Knowledge Organization‚Äô. Information Processing &
   Management 49 no. 6: 1313‚Äì25.
   https://doi.org/10.1016/j.ipm.2013.07.001.

   Hyland, Ken, and Fran√ßoise Salager-Meyer. 2009. ‚ÄòScientific Writing‚Äô.
   Annual Review of Information Science and Technology 42 no. 1: 297‚Äì338.
   https://doi.org/10.1002/aris.2008.1440420114.

   ICMJE, International Committee of Medical Journal Editors. 2019.
   ‚ÄòRecommendations for the Conduct, Reporting, Editing, and Publication
   of Scholarly Work in Medical Journals‚Äô.
   http://www.icmje.org/icmje-recommendations.pdf.

   Jaffe, Adam B., and Manuel Trajtenberg. 2002. Patents, Citations, and
   Innovations: A Window on the Knowledge Economy. Cambridge, Mass: MIT
   Press.

   Jones, William P, and George W Furnas. 1987. ‚ÄòPictures of Relevance: A
   Geomatric Analysis of Similarity Measures‚Äô. Journal of the American
   Society for Information Science 38 no. 6: 420‚Äì42.

   Kaplan, N. 1965. ‚ÄòThe Norms of Citation Behavior. Prolegomena to the
   Footnote‚Äô. American Documentation 16 no. 3: 179‚Äì87.

   Katz, J.Sylvan, and Ben R. Martin. 1997. ‚ÄòWhat Is Research
   Collaboration?‚Äô Research Policy 26 no. 1: 1‚Äì18.
   https://doi.org/10.1016/S0048-7333(96)00917-1.

   Kessler, M.M. 1963. ‚ÄòBibliographic Coupling Extended in Time: Ten Case
   Histories‚Äô. Information Storage and Retrieval 1 no. 4: 169‚Äì87.
   https://doi.org/10.1016/0020-0271(63)90016-0.

   Knorr-Cetina, K. 2003. Epistemic Cultures: How the Sciences Make
   Knowledge. Cambridge Mass. [etc.]: Harvard University Press.

   Kreuzman, Henry. 2001. ‚ÄòA Co-Citation Analysis of Representative
   Authors in Philosophy: Examining the Relationship between
   Epistemologists and Philosophers of Science‚Äô. Scientometrics 51 no. 3:
   525‚Äì39.

   Kuhn, Thomas S. 2000. The Road since Structure: Philosophical Essays,
   1970-1993, with an Autobiographical Interview. Edited by James Conant
   and John Haugeland. Chicago: University of Chicago Press.

   Larivi√®re, Vincent, Nadine Desrochers, Beno√Æt Macaluso, Philippe
   Mongeon, Ad√®le Paul-Hus, and Cassidy R. Sugimoto. 2016.
   ‚ÄòContributorship and Division of Labor in Knowledge Production‚Äô. Social
   Studies of Science 46 no. 3: 417‚Äì35.
   https://doi.org/10.1177/0306312716650046.

   Latour, Bruno. 2003. Science in Action: How to Follow Scientists and
   Engineers through Society. 11. print. Cambridge, Mass: Harvard
   University Press.

   Latour, Bruno, and Steve Woolgar. 1986. Laboratory Life: The
   Construction of Scientific Facts. Princeton, N.J: Princeton University
   Press.

   Laudel, Grit. 2002. ‚ÄòWhat Do We Measure by Co-Authorships?‚Äô Research
   Evaluation 11 no. 1: 3‚Äì15. https://doi.org/10.3152/147154402781776961.

   Laurens, Patricia, Michel Zitt, and Elise Bassecoulard. 2010.
   ‚ÄòDelineation of the Genomics Field by Hybrid Citation-Lexical Methods:
   Interaction with Experts and Validation Process‚Äô. Scientometrics 82 no.
   3: 647‚Äì62. https://doi.org/10.1007/s11192-010-0177-9.

   Law, J., and J. Whittaker. 1992. ‚ÄòMapping Acidification Research: A
   Test of the Co-Word Method‚Äô. Scientometrics 23 no. 3: 417‚Äì61.
   https://doi.org/10.1007/BF02029807.

   Lee, Sungjoo, Byungun Yoon, and Yongtae Park. 2009. ‚ÄòAn Approach to
   Discovering New Technology Opportunities: Keyword-Based Patent Map
   Approach‚Äô. Technovation 29 no. 6‚Äì7: 481‚Äì97.
   https://doi.org/10.1016/j.technovation.2008.10.006.

   Leydesdorff, Loet. 1987. ‚ÄòVarious Methods for the Mapping of Science‚Äô.
   Scientometrics 11 no. 5‚Äì6: 295‚Äì324. https://doi.org/10.1007/BF02279351.

   Leydesdorff, Loet. 1997. ‚ÄòWhy Words and Co-words Cannot Map the
   Development of the Sciences‚Äô. Journal of the American Society for
   Information Science 48 no. 5: 418.

   Leydesdorff, Loet. 2001. The Challenge of Scientometrics: The
   Development, Measurement, and Self-Organization of Scientific
   Communications. 2. ed. Parkland, Ill.: Universal Publ.

   Leydesdorff, Loet. 2004. ‚ÄòClusters and Maps of Science Journals Based
   on Bi-connected Graphs in Journal Citation Reports‚Äô. Journal of
   Documentation 60 no. 4: 371‚Äì427.
   https://doi.org/10.1108/00220410410548144.

   Leydesdorff, Loet. 2007. ‚ÄòBetweenness Centrality as an Indicator of the
   Interdisciplinarity of Scientific Journals‚Äô. Journal of the American
   Society for Information Science and Technology 58 no. 9: 1303‚Äì19.
   https://doi.org/10.1002/asi.20614.

   Leydesdorff, Loet. 2008. ‚ÄòOn the Normalization and Visualization of
   Author Co-Citation Data: Salton‚Äôs Cosine versus the Jaccard Index‚Äô.
   Journal of the American Society for Information Science and Technology
   59 no. 1: 77‚Äì85. https://doi.org/10.1002/asi.20732.

   Leydesdorff, Loet, and Robert L. Goldstone. 2014. ‚ÄòInterdisciplinarity
   at the Journal and Specialty Level: The Changing Knowledge Bases of the
   Journal Cognitive Science‚Äô. Journal of the Association for Information
   Science and Technology 65 no. 1: 164‚Äì77.
   https://doi.org/10.1002/asi.22953.

   Leydesdorff, Loet, and Olle Persson. 2010. ‚ÄòMapping the Geography of
   Science: Distribution Patterns and Networks of Relations among Cities
   and Institutes‚Äô. Journal of the American Society for Information
   Science and Technology 61 no. 8: 1622-1634.
   https://doi.org/10.1002/asi.21347.

   Leydesdorff, Loet, and Ismael Rafols. 2009. ‚ÄòA Global Map of Science
   Based on the ISI Subject Categories‚Äô. Journal of the American Society
   for Information Science and Technology 60 no. 2: 348‚Äì62.
   https://doi.org/10.1002/asi.20967.

   Leydesdorff, Loet, and Thomas Schank. 2008. ‚ÄòDynamic Animations of
   Journal Maps: Indicators of Structural Changes and Interdisciplinary
   Developments‚Äô. Journal of the American Society for Information Science
   and Technology 59 no. 11: 1810‚Äì18. https://doi.org/10.1002/asi.20891.

   Lima, Manuel. 2014. The Book of Trees: Visualizing Branches of
   Knowledge. First edition. New York: Princeton Architectural Press.

   Liu, Xiaoming, Johan Bollen, Michael L. Nelson, and Herbert Van de
   Sompel. 2005. ‚ÄòCo-Authorship Networks in the Digital Library Research
   Community‚Äô. Information Processing & Management 41 no. 6: 1462‚Äì80.
   https://doi.org/10.1016/j.ipm.2005.03.012.

   Livingstone, David N. 2003. Putting Science in Its Place: Geographies
   of Scientific Knowledge. Science.Culture. Chicago: University of
   Chicago Press.

   Lucio-Arias, Diana, and Loet Leydesdorff. 2009. ‚ÄòThe Dynamics of
   Exchanges and References among Scientific Texts, and the Autopoiesis of
   Discursive Knowledge‚Äô. Journal of Informetrics 3 no. 3: 261‚Äì71.
   https://doi.org/10.1016/j.joi.2009.03.003.

   MacRoberts, Michael H., and Barbara R. MacRoberts. 2018. ‚ÄòThe
   Mismeasure of Science: Citation Analysis‚Äô. Journal of the Association
   for Information Science and Technology 69 no. 3: 474‚Äì82.
   https://doi.org/10.1002/asi.23970.

   Marshakova, Irena. 1973. ‚ÄòSystem of Document Connections Based On
   References‚Äô. Nauchno-Tekhnicheskaya Informatsiya Seriya
   2-Informatsionnye Protsessy I Sistemy 2 no. 6: 3‚Äì8.

   Mazzocchi, Fulvio. 2018. ‚ÄòKnowledge Organization System (KOS)‚Äô.
   Knowledge Organization 45 no. 1: 54‚Äì78. Also available in ISKO
   Encyclopedia of Knowledge Organization, eds. Birger Hj√∏rland and
   Claudio Gnoli, https://www.isko.org/cyclo/kos.

   McCain, Katherine W. 1990. ‚ÄòMapping Authors in Intellectual Space: A
   Technical Overview‚Äô. Journal of the American Society for Information
   Science 41 no. 6: 433‚Äì43.

   McCain, Katherine W. 1991. ‚ÄòMapping Economics through the Journal
   Literature: An Experiment in Journal Cocitation Analysis‚Äô. Journal of
   the American Society for Information Science 42 no. 4: 290‚Äì96.
   3.0.CO;2-9">https://doi.org/10.1002/(SICI)1097-4571(199105)42:4<290::AI
   D-ASI5>3.0.CO;2-9.

   Merton, Robert K. 1974. The Sociology of Science: Theoretical and
   Empirical Investigations. 4. Dr. Chicago: Univ. of Chicago Pr.

   Meyer, Martin. 2000. ‚ÄòDoes Science Push Technology? Patents Citing
   Scientific Literature‚Äô. Research Policy 29 no. 3: 409‚Äì34.
   https://doi.org/10.1016/S0048-7333(99)00040-2.

   Moral-Munoz, Jose A., Antonio G. L√≥pez-Herrera, Enrique Herrera-Viedma,
   and Manuel J. Cobo. 2019. ‚ÄòScience Mapping Analysis Software Tools: A
   Review‚Äô. In Springer Handbook of Science and Technology Indicators,
   edited by Wolfgang Gl√§nzel, Henk F. Moed, Ulrich Schmoch, and Mike
   Thelwall, 159‚Äì85. Springer Handbooks. Cham: Springer International
   Publishing. https://doi.org/10.1007/978-3-030-02511-3_7.

   Murray, Fiona. 2002. ‚ÄòInnovation as Co-Evolution of Scientific and
   Technological Networks: Exploring Tissue Engineering‚Äô. Research Policy
   31 no. 8‚Äì9: 1389‚Äì1403. https://doi.org/10.1016/S0048-7333(02)00070-7.

   Mutschke, Peter, and Anabel Quan-Haase. 2001. ‚ÄòCollaboration and
   Cognitive Structures in Social Science Research Fields. Towards
   Socio-Cognitive Analysis in Information Systems.‚Äô Scientometrics 52 no.
   3: 487‚Äì502.

   Nederhof, Anton J. 2006. ‚ÄòBibliometric Monitoring of Research
   Performance in the Social Sciences and the Humanities: A Review‚Äô.
   Scientometrics 66 no. 1: 81‚Äì100.
   https://doi.org/10.1007/s11192-006-0007-2.

   Newman, M. E. 2001. ‚ÄòScientific Collaboration Networks. I. Network
   Construction and Fundamental Results‚Äô. Physical Review. E, Statistical,
   Nonlinear, and Soft Matter Physics 64 no. 1: 16131.

   Nicolaisen, Jeppe. 2007. ‚ÄòCitation Analysis‚Äô. Annual Review of
   Information Science and Technology 41 no. 1: 609‚Äì41.
   https://doi.org/10.1002/aris.2007.1440410120.

   Noyons, Ed C. M., and Clara Calero-Medina. 2009. ‚ÄòApplying Bibliometric
   Mapping in a High Level Science Policy Context: Mapping the Research
   Areas of Three Dutch Universities of Technology‚Äô. Scientometrics 79 no.
   2: 261‚Äì75. https://doi.org/10.1007/s11192-009-0417-z.

   Osinska, Veslava and Piotr Malak. 2016. ‚ÄúMaps and Mapping in
   Scientometrics‚Äù. In Metody i narzeÃ®dzia badanÃÅ pisÃÅmiennictwa cyfrowego
   i jego uzÃáytkownikoÃÅw [Methods and Tools for Researching Digital
   Writing and Its Users]. Eds. Malgorzata G√≥ralska and Agnieszka Wandel.
   Wroc≈Çaw: Wroc≈Çaw University, 59-72.

   Pan, Xuelian, Erjia Yan, Ming Cui, and Weina Hua. 2018. ‚ÄòExamining the
   Usage, Citation, and Diffusion Patterns of Bibliometric Mapping
   Software: A Comparative Study of Three Tools‚Äô. Journal of Informetrics
   12 no. 2: 481‚Äì93. https://doi.org/10.1016/j.joi.2018.03.005.

   Persson, Olle. 1994. ‚ÄòThe Intellectual Base and Research Fronts of
   JASIS 1986‚Äì1990‚Äô. Journal of the American Society for Information
   Science 45 no. 1: 31‚Äì38.

   Petrovich, Eugenio. 2018. ‚ÄòAccumulation of Knowledge in Para-Scientific
   Areas: The Case of Analytic Philosophy‚Äô. Scientometrics 116 no. 2:
   1123‚Äì51. https://doi.org/10.1007/s11192-018-2796-5.

   Petrovich, Eugenio. 2019a. ‚ÄòThe Fabric of Knowledge: Towards a
   Documental History of Late Analytic Philosophy‚Äô. Ph.D. Dissertation,
   Milan: University of Milan. https://air.unimi.it/handle/2434/613334.

   Petrovich, Eugenio. 2019b. ‚ÄòThe Structure of Scientific Disciplines.
   Some Notes on the Epistemology of Algorithmic Representations of
   Disciplines‚Äô. In STOREP 2019. University of Siena.
   http://conference.storep.org/‚Ä¶.

   Petrovich, Eugenio, and Valerio Buonomo. 2018. ‚ÄòReconstructing Late
   Analytic Philosophy. A Quantitative Approach‚Äô. Philosophical Inquiries
   6 no. 1. https://doi.org/10.4454/philinq.v6i1.184.

   Petrovich, Eugenio, and Emiliano Tolusso. 2019. ‚ÄòExploring Knowledge
   Dynamics in the Humanities. Two Science Mapping Experiments‚Äô. Journal
   of Interdisciplinary History of Ideas 8 no. 16: 1‚Äì30.
   http://dx.doi.org/10.13135/2280-8574/4304.

   Price, Derek J. de Solla. 1965. ‚ÄòNetworks of Scientific Papers‚Äô.
   Science 149 no. 3683: 510‚Äì15.
   https://doi.org/10.1126/science.149.3683.510.

   Radicchi, F., S. Fortunato, and A Vespignani. 2012. ‚ÄòCitation
   Networks‚Äô. In Models of Science Dynamics: Encounters between Complexity
   Theory and Information Sciences, edited by Andrea Scharnhorst, Katy
   B√∂rner, and Peter van den Besselaar. Understanding Complex Systems.
   Heidelberg-New York: Springer.

   Radicchi, F., Santo Fortunato, Benjamin Markines, and Alessandro
   Vespignani. 2009. ‚ÄòDiffusion of Scientific Credits and the Ranking of
   Scientists‚Äô. Physical Review E 80 no. 5: 056103.
   https://doi.org/10.1103/PhysRevE.80.056103.

   Rafols, Ismael, Alan L. Porter, and Loet Leydesdorff. 2010. ‚ÄòScience
   Overlay Maps: A New Tool for Research Policy and Library Management‚Äô.
   Journal of the American Society for Information Science and Technology
   61 no. 9: 1871‚Äì87. https://doi.org/10.1002/asi.21368.

   Ranaei, Samira, Arho Suominen, Alan Porter, and Tuomo K√§ssi. 2019.
   ‚ÄòApplication of Text-Analytics in Quantitative Study of Science and
   Technology‚Äô. In Springer Handbook of Science and Technology Indicators,
   edited by Wolfgang Gl√§nzel, Henk F. Moed, Ulrich Schmoch, and Mike
   Thelwall, 957‚Äì82. Springer Handbooks. Cham: Springer International
   Publishing. https://doi.org/10.1007/978-3-030-02511-3_39.

   Reiss, Julian, and Jan Sprenger. 2017. ‚ÄòScientific Objectivity‚Äô. In The
   Stanford Encyclopedia of Philosophy, edited by Edward N. Zalta, Winter
   2017. Metaphysics Research Lab, Stanford University.
   https://plato.stanford.edu/archives/win2017/entries/scientific-objectiv
   ity/.

   Rosvall, Martin, and Carl T. Bergstrom. 2010. ‚ÄòMapping Change in Large
   Networks‚Äô. Edited by Fabio Rapallo. PLoS ONE 5 no. 1: e8694.
   https://doi.org/10.1371/journal.pone.0008694.

   Salton, Gerard, and Michael J. McGill. 1983. Introduction to Modern
   Information Retrieval. McGraw-Hill Computer Science Series. New York:
   McGraw-Hill.

   Scharnhorst, Andrea, Katy B√∂rner, and Peter van den Besselaar, eds.
   2012. Models of Science Dynamics: Encounters between Complexity Theory
   and Information Sciences. Understanding Complex Systems. Heidelberg-New
   York: Springer.

   Skupin, Andr√©, Joseph R. Biberstine, and Katy B√∂rner. 2013.
   ‚ÄòVisualizing the Topical Structure of the Medical Sciences: A
   Self-Organizing Map Approach‚Äô. Edited by Matthias Dehmer. PLoS ONE 8
   no. 3: e58779. https://doi.org/10.1371/journal.pone.0058779.

   Small, Henry. 1973. ‚ÄòCo-Citation in the Scientific Literature: A New
   Measure of the Relationship between Two Documents‚Äô. Journal of the
   American Society for Information Science 24 no. 4: 265‚Äì69.
   https://doi.org/10.1002/asi.4630240406.

   Small, Henry. 1977. ‚ÄòA Co-Citation Model of a Scientific Specialty: A
   Longitudinal Study of Collagen Research‚Äô. Social Studies of Science 7
   no. 2: 139‚Äì66. https://doi.org/10.1177/030631277700700202.

   Small, Henry. 1999. ‚ÄòVisualizing Science by Citation Mapping‚Äô. Journal
   of the American Society for Information Science 50 no. 9: 799‚Äì813.
   3.0.CO;2-G">https://doi.org/10.1002/(SICI)1097-4571(1999)50:9<799::AID-
   ASI9>3.0.CO;2-G.

   Small, Henry, and Belver C. Griffith. 1974. ‚ÄòThe Structure of
   Scientific Literatures I: Identifying and Graphing Specialties‚Äô.
   Science Studies 4 no. 1: 17‚Äì40.
   https://doi.org/10.1177/030631277400400102.

   Sp√§rck Jones, Karen. 1972. ‚ÄòA statistical interpretation of term
   specificity and its application to retrieval‚Äô. Journal of Documentation
   28 no. 1: 11‚Äì21. https://doi.org/10.1108/eb026526.

   Strotmann, Andreas, and Dangzhi Zhao. 2012. ‚ÄòAuthor Name
   Disambiguation: What Difference Does It Make in Author-Based Citation
   Analysis?‚Äô Journal of the American Society for Information Science and
   Technology 63 no. 9: 1820‚Äì33. https://doi.org/10.1002/asi.22695.

   Sugimoto, Cassidy R., and Scott Weingart. 2015. ‚ÄòThe Kaleidoscope of
   Disciplinarity‚Äô. Journal of Documentation 71 no. 4: 775‚Äì94.
   https://doi.org/10.1108/JD-06-2014-0082.

   Swales, John M. 2004. Research Genres: Explorations and Applications.
   Cambridge Applied Linguistics Series. Cambridge, UK?; New York:
   Cambridge University Press.

   Tahamtan, Iman, and Lutz Bornmann. 2018. ‚ÄòCore Elements in the Process
   of Citing Publications: Conceptual Overview of the Literature‚Äô. Journal
   of Informetrics 12 no. 1: 203‚Äì16.
   https://doi.org/10.1016/j.joi.2018.01.002.

   Tahamtan, Iman, and Lutz Bornmann. 2019. ‚ÄòWhat Do Citation Counts
   Measure? An Updated Review of Studies on Citations in Scientific
   Documents Published between 2006 and 2018‚Äô. Scientometrics 121 no. 3:
   1635‚Äì84. https://doi.org/10.1007/s11192-019-03243-4.

   Taheo, Jo. 2018. Text Mining: Concepts, Implementation, and Big Data
   Challenge. Vol. 45. Studies in Big Data. New York, NY: Springer
   Science+Business Media.

   Thijs, Bart. 2019. ‚ÄòScience Mapping and the Identification of Topics:
   Theoretical and Methodological Considerations‚Äô. In Springer Handbook of
   Science and Technology Indicators, edited by Wolfgang Gl√§nzel, Henk F.
   Moed, Ulrich Schmoch, and Mike Thelwall, 213‚Äì33. Springer Handbooks.
   Cham: Springer International Publishing.
   https://doi.org/10.1007/978-3-030-02511-3_9.

   Tijssen, R. J. W. 1993. ‚ÄòA Scientometric Cognitive Study of Neural
   Network Research: Expert Mental Maps versus Bibliometric Maps‚Äô.
   Scientometrics 28 no. 1: 111‚Äì36. https://doi.org/10.1007/BF02016288.

   Townsend, Keith, and John (K John) Burgess, eds. 2009. Method in the
   Madness? Research Stories You Won‚Äôt Find in a Textbook. Oxford:
   Chandos.

   Tseng, Yuen-Hsien, Chi-Jen Lin, and Yu-I Lin. 2007. ‚ÄòText Mining
   Techniques for Patent Analysis‚Äô. Information Processing & Management 43
   no. 5: 1216‚Äì47. https://doi.org/10.1016/j.ipm.2006.11.011.

   Van Raan, Anthony F. J. 1998. ‚ÄòIn Matters of Quantitative Studies of
   Science the Fault of Theorists Is Offering Too Little and Asking Too
   Much‚Äô. Scientometrics 43 no. 1: 129‚Äì39.
   https://doi.org/10.1007/BF02458401.

   Van Raan, Anthony F. J. 2019. ‚ÄòMeasuring Science: Basic Principles and
   Application of Advanced Bibliometrics‚Äô. In Springer Handbook of Science
   and Technology Indicators, edited by Wolfgang Gl√§nzel, Henk F. Moed,
   Ulrich Schmoch, and Mike Thelwall, 237‚Äì80. Springer Handbooks. Cham:
   Springer International Publishing.
   https://doi.org/10.1007/978-3-030-02511-3_10.

   Van Raan, Anthony F. J., and R. J. W. Tijssen. 1993. ‚ÄòThe Neural Net of
   Neural Network Research: An Exercise in Bibliometric Mapping‚Äô.
   Scientometrics 26 no. 1: 169‚Äì92. https://doi.org/10.1007/BF02016799.

   Visser, Martijn, Nees Jan van Eck, and Ludo Waltman. 2020. ‚ÄòLarge-Scale
   Comparison of Bibliographic Data Sources: Scopus, Web of Science,
   Dimensions, Crossref, and Microsoft Academic‚Äô. ArXiv:2005.10732 [Cs],
   May. http://arxiv.org/abs/2005.10732.

   Waltman, Ludo, and Nees Jan van Eck. 2012. ‚ÄòA New Methodology for
   Constructing a Publication-Level Classification System of Science‚Äô.
   Journal of the American Society for Information Science and Technology
   63 no. 12: 2378‚Äì92. https://doi.org/10.1002/asi.22748.

   Waltman, Ludo, and Nees Jan van Eck. 2014. ‚ÄòVisualizing Bibliometric
   Networks‚Äô. In Measuring Scholarly Impact: Methods and Practice,
   285‚Äì320. Springer.

   Waltman, Ludo, Nees Jan van Eck, and Ed C.M. Noyons. 2010. ‚ÄòA Unified
   Approach to Mapping and Clustering of Bibliometric Networks‚Äô. Journal
   of Informetrics 4 no. 4: 629‚Äì35.
   https://doi.org/10.1016/j.joi.2010.07.002.

   Wartburg, Iwan von, Thorsten Teichert, and Katja Rost. 2005. ‚ÄòInventive
   Progress Measured by Multi-Stage Patent Citation Analysis‚Äô. Research
   Policy 34 no. 10: 1591‚Äì1607.
   https://doi.org/10.1016/j.respol.2005.08.001.

   Wasserman, Stanley, and Katherine Faust. 1994. Social Network Analysis:
   Methods and Applications. Structural Analysis in the Social Sciences 8.
   Cambridge-New York: Cambridge University Press.

   Weingart, Scott B. 2015. ‚ÄòFinding the History and Philosophy of
   Science‚Äô. Erkenntnis 80 no. 1: 201‚Äì13.
   https://doi.org/10.1007/s10670-014-9621-1.

   White, Howard D., and Belver C. Griffith. 1981. ‚ÄòAuthor Cocitation: A
   Literature Measure of Intellectual Structure‚Äô. Journal of the American
   Society for Information Science 32 no. 3: 163‚Äì71.
   https://doi.org/10.1002/asi.4630320302.

   White, Howard D., and Katherine W. McCain. 1998. ‚ÄòVisualizing a
   Discipline: An Author Co-Citation Analysis of Information Science, 1972
   - 1995‚Äô. Journal of the American Society for Information Science 49 no.
   4: 327.

   Wichmann Matthiessen, Christian, Annette Winkel Schwarz, and S√∏ren
   Find. 2002. ‚ÄòThe Top-Level Global Research System, 1997-99: Centres,
   Networks and Nodality. An Analysis Based on Bibliometric Indicators‚Äô.
   Urban Studies 39 no. 5‚Äì6: 903‚Äì27.
   https://doi.org/10.1080/00420980220128372.

   Wislar, J. S., A. Flanagin, P. B. Fontanarosa, and C. D. DeAngelis.
   2011. ‚ÄòHonorary and Ghost Authorship in High Impact Biomedical
   Journals: A Cross Sectional Survey‚Äô. BMJ 343 no. oct25 1: d6128‚Äìd6128.
   https://doi.org/10.1136/bmj.d6128.

   Wouters, Paul. 1999a. The Citation Culture. Unpublished PhD thesis.

   Wouters, Paul. 1999b. ‚ÄòBeyond the Holy Grail: From Citation Theory to
   Indicator Theories‚Äô. Scientometrics 44 no. 3: 561‚Äì80.
   https://doi.org/10.1007/BF02458496.

   Zhao, Dangzhi. 2009. ‚ÄòMapping Library and Information Science: Does
   Field Delineation Matter?‚Äô Proceedings of the American Society for
   Information Science and Technology 46 no. 1: 1‚Äì11.
   https://doi.org/10.1002/meet.2009.1450460279.

   Zhou, Qiuju, and Loet Leydesdorff. 2016. ‚ÄòThe Normalization of
   Occurrence and Co-Occurrence Matrices in Bibliometrics Using Cosine
   Similarities and Ochiai Coefficients‚Äô. Journal of the Association for
   Information Science and Technology 67 no. 11: 2805‚Äì14.
   https://doi.org/10.1002/asi.23603.

   Zitt, Michel, and Elise Bassecoulard. 2006. ‚ÄòDelineating Complex
   Scientific Fields by an Hybrid Lexical-Citation Method: An Application
   to Nanosciences‚Äô. Information Processing & Management 42 no. 6:
   1513‚Äì31. https://doi.org/10.1016/j.ipm.2006.03.016.

   Zitt, Michel, Alain Lelu, Martine Cadot, and Guillaume Cabanac. 2019.
   ‚ÄòBibliometric Delineation of Scientific Fields‚Äô. In Springer Handbook
   of Science and Technology Indicators, edited by Wolfgang Gl√§nzel, Henk
   F. Moed, Ulrich Schmoch, and Mike Thelwall, 25‚Äì68. Springer Handbooks.
   Cham: Springer International Publishing.
   https://doi.org/10.1007/978-3-030-02511-3_2.

                                                            [top of entry]

Appendix: Science mapping tools

   Science maps can be generated by any general software of graph analysis
   and visualization, such as Pajek and Gephi. However, in the last years,
   several dedicated tools have been developed specifically for science
   mapping, such as VOSviewer, CiteSpace, HistCite, Sci2 Tool, SciMAT,
   Bibexcel, and CitNetExplorer. In this section, we briefly present
   CiteSpace and VOSviewer, the two most popular science mapping tools
   (Pan et al. 2018). They are both free, constantly updated, and provided
   with extended user-guides. A full description of these and other tools
   can be found in (Moral-Munoz et al. 2019).

CiteSpace

   CiteSpacei was developed by Chaomei Chen in 2004 at Drexel University
   (USA) (Chen 2006). Since its first version, it has a special focus on
   the temporal dynamics of scientific networks. Its primary goal is to
   detect emerging trends and bursts of interest in a knowledge domain.
   Therefore, the visualizations it produces pay special attention to the
   dynamical aspects of the mapped domain: for instance, the number of
   citations received by an article is visualized as ‚Äúcitation tree
   rings‚Äù, in which the thickness of each ring is proportional to the
   number of citation received in a given time slice. CiteSpace also
   highlights ‚Äúpivotal points‚Äù in the emergence of new specialties, i.e.,
   articles denoted by high betweenness centrality that bridge across
   different co-citation clusters.

   After the dataset is downloaded from Web of Science, Scopus, or other
   compatible bibliographic databases, CiteSpace allows to manage the
   entire workflow of science mapping. The network can be extracted from
   the data choosing different entities as nodes (author, institution,
   journal, country, cited publication, terms, keywords, etc.). The
   dataset can be split into time slices and the most relevant items
   according to some threshold can be selected (e.g., top-cited papers in
   each time slice). CiteSpace offers different methods to normalize the
   raw values and to ‚Äúprune‚Äù the network in order to retain the most
   relevant links. Maps can be generated both in the form of graph-based
   visualizations, and timeline-based visualizations. The visualization
   tool allows controlling each feature of the map, from the layout to the
   labels of nodes, links, and clusters, to navigate the map, and to
   select specific nodes by clicking on them. Tools for clustering,
   automatic extraction of clusters‚Äô labels, citation burst detection, and
   other analyses are included.

   CiteSpace is a very powerful software and it produces aesthetically
   impressive visualizations. However, it needs some expertise to fully
   take advantage of all its features. We suggest it to advanced users who
   already have some skills in science mapping.

VOSviewer

   VOSviewerii was developed by Nees Jan van Eck and Ludo Waltman in 2010
   at the Center for Science and Technology Studies (CWTS) in Leiden (The
   Netherlands) (Eck and Waltman 2010). If the first versions of the tool
   focused only on the visualization of bibliometric networks, the new
   versions allow to manage the entire workflow of science mapping. A
   special feature of VOSviewer is that it produces only distance-based
   visualizations, using a dedicated technique called VOS mapping
   technique, where VOS stands for ‚Äúvisualization of similarity‚Äù (Eck et
   al. 2010). Such a technique is a variant of multi-dimensional scaling
   that avoids some visual artifacts generated by classic MDS methods (see
   Section 4.1.4: Visualization).

   VOSviewer can create maps based on any network data (e.g., Pajek
   network files) but it can also extract the network from bibliometric
   data. It supports data from Web of Science, Scopus, PubMed, and other
   databases. The ‚ÄúCreate map wizard‚Äù allows the user to extract from the
   data several kinds of networks. Possible nodes include publications,
   journals, authors, research organizations, countries, keywords, terms.
   Links can be co-authorship, co-occurrence, direct citation,
   bibliographic coupling or co-citation links. Moreover, VOSviewer uses a
   dedicated clustering technique, based on modularity, to find groups of
   similar nodes (Waltman, van Eck and Noyons 2010). The nodes are then
   colored according to the cluster they belong to. The size of the nodes
   and links is used to show some nodes or links property, such as the
   number of citations and co-occurrences. VOSviewer offers three
   visualizations of a map: the network visualization, the overlay
   visualization, and the density visualization. Zooming and scrolling
   functionalities allow exploring in detail the map. In the overlay
   visualization, properties of the nodes different from their cluster
   (e.g., the Impact Factor of a journal in a journal map), can be shown
   in different colors.

   Compared to CiteSpace, VOSviewer is less focused on the dynamical
   aspects of knowledge domains and offers fewer tools for the analysis of
   science maps. However, it is very easy to use, the create map wizard is
   intuitive, and the distance-based visualization facilitates the
   interpretation of the maps. We suggest it to the novices and to
   professionals who need a user-friendly tool for science mapping.

                                                            [top of entry]


   Visited Hit Counter by Digits times.
     __________________________________________________________________

   Version 1.0 published 2020-06-10
   Version 1.1 published 2021-04-26: reference to Osinska and Malak added

   Article category: KO in different contexts and applications

   This article (version 1.0) is also published in Knowledge Organization.
   How to cite it:
   Petrovich, Eugenio. 2021. ‚ÄúScience mapping and science maps‚Äù. Knowledge
   Organization 48, no. 7-8: 535‚Äì562. Also available in ISKO Encyclopedia
   of Knowledge Organization, eds. Birger Hj√∏rland and Claudio Gnoli,
   https://www.isko.org/cyclo/science-mapping

   ¬©2020 ISKO. All rights reserved.
